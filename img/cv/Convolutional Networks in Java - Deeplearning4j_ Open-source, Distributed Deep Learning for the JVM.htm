<!DOCTYPE html>
<!-- saved from url=(0044)https://deeplearning4j.org/convolutionalnets -->
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en-us"><script type="text/javascript" async="" src="./Convolutional Networks in Java - Deeplearning4j_ Open-source, Distributed Deep Learning for the JVM_files/widgets.js"></script><script type="text/javascript" async="" src="./Convolutional Networks in Java - Deeplearning4j_ Open-source, Distributed Deep Learning for the JVM_files/linkid.js"></script><script src="./Convolutional Networks in Java - Deeplearning4j_ Open-source, Distributed Deep Learning for the JVM_files/5605.js" async="" type="text/javascript"></script><script id="upvert-loader" src="./Convolutional Networks in Java - Deeplearning4j_ Open-source, Distributed Deep Learning for the JVM_files/loader.js" type="text/javascript" async=""></script><script id="hs-analytics" src="./Convolutional Networks in Java - Deeplearning4j_ Open-source, Distributed Deep Learning for the JVM_files/2179705.js"></script><script async="" src="./Convolutional Networks in Java - Deeplearning4j_ Open-source, Distributed Deep Learning for the JVM_files/analytics.js"></script><script type="text/javascript" src="chrome-extension://eoknmaajkanapojcdeccofmeimpddoim/xhr_overload.js"></script><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<style>.gitter-hidden{box-sizing:border-box;display:none}.gitter-icon{box-sizing:border-box;width:22px;height:22px;fill:currentColor}.gitter-chat-embed{box-sizing:border-box;z-index:100;position:fixed;top:0;left:60%;bottom:0;right:0;display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:horizontal;-webkit-box-direction:normal;-ms-flex-direction:row;flex-direction:row;background-color:#fff;border-left:1px solid #333;box-shadow:-12px 0 18px 0 rgba(50,50,50,.3);-webkit-transition:-webkit-transform .3s cubic-bezier(.16,.22,.22,1.7);transition:-webkit-transform .3s cubic-bezier(.16,.22,.22,1.7);transition:transform .3s cubic-bezier(.16,.22,.22,1.7);transition:transform .3s cubic-bezier(.16,.22,.22,1.7),-webkit-transform .3s cubic-bezier(.16,.22,.22,1.7)}@context border-box{.gitter-chat-embed{box-sizing:border-box;background-color:#fff}}.gitter-chat-embed.is-collapsed:not(.is-loading){box-sizing:border-box;-webkit-transform:translateX(110%);transform:translateX(110%)}.gitter-chat-embed:after{box-sizing:border-box;content:'';z-index:-1;position:absolute;top:0;left:100%;bottom:0;right:-100%;background-color:#fff}@context border-box{.gitter-chat-embed:after{box-sizing:border-box;background-color:#fff}}@media(max-width:1150px){.gitter-chat-embed{box-sizing:border-box;left:45%}}@media(max-width:944px){.gitter-chat-embed{box-sizing:border-box;left:30%}}@media(max-width:600px){.gitter-chat-embed{box-sizing:border-box;left:15%}}@media(max-width:500px){.gitter-chat-embed{box-sizing:border-box;left:0;border-left:none}}.gitter-chat-embed>iframe{box-sizing:border-box;-webkit-box-flex:1;-ms-flex:1;flex:1;width:100%;height:100%;border:0}.gitter-chat-embed-loading-wrapper{box-sizing:border-box;position:absolute;top:0;left:0;bottom:0;right:0;display:none;-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;-webkit-box-align:center;-ms-flex-align:center;-ms-grid-row-align:center;align-items:center}.is-loading .gitter-chat-embed-loading-wrapper{box-sizing:border-box;display:-webkit-box;display:-ms-flexbox;display:flex}.gitter-chat-embed-loading-indicator{box-sizing:border-box;opacity:.75;background-image:url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAxNzkyIDE3OTIiIGZpbGw9IiMzYTMxMzMiPjxwYXRoIGQ9Ik01MjYgMTM5NHEwIDUzLTM3LjUgOTAuNXQtOTAuNSAzNy41cS01MiAwLTkwLTM4dC0zOC05MHEwLTUzIDM3LjUtOTAuNXQ5MC41LTM3LjUgOTAuNSAzNy41IDM3LjUgOTAuNXptNDk4IDIwNnEwIDUzLTM3LjUgOTAuNXQtOTAuNSAzNy41LTkwLjUtMzcuNS0zNy41LTkwLjUgMzcuNS05MC41IDkwLjUtMzcuNSA5MC41IDM3LjUgMzcuNSA5MC41em0tNzA0LTcwNHEwIDUzLTM3LjUgOTAuNXQtOTAuNSAzNy41LTkwLjUtMzcuNS0zNy41LTkwLjUgMzcuNS05MC41IDkwLjUtMzcuNSA5MC41IDM3LjUgMzcuNSA5MC41em0xMjAyIDQ5OHEwIDUyLTM4IDkwdC05MCAzOHEtNTMgMC05MC41LTM3LjV0LTM3LjUtOTAuNSAzNy41LTkwLjUgOTAuNS0zNy41IDkwLjUgMzcuNSAzNy41IDkwLjV6bS05NjQtOTk2cTAgNjYtNDcgMTEzdC0xMTMgNDctMTEzLTQ3LTQ3LTExMyA0Ny0xMTMgMTEzLTQ3IDExMyA0NyA0NyAxMTN6bTExNzAgNDk4cTAgNTMtMzcuNSA5MC41dC05MC41IDM3LjUtOTAuNS0zNy41LTM3LjUtOTAuNSAzNy41LTkwLjUgOTAuNS0zNy41IDkwLjUgMzcuNSAzNy41IDkwLjV6bS02NDAtNzA0cTAgODAtNTYgMTM2dC0xMzYgNTYtMTM2LTU2LTU2LTEzNiA1Ni0xMzYgMTM2LTU2IDEzNiA1NiA1NiAxMzZ6bTUzMCAyMDZxMCA5My02NiAxNTguNXQtMTU4IDY1LjVxLTkzIDAtMTU4LjUtNjUuNXQtNjUuNS0xNTguNXEwLTkyIDY1LjUtMTU4dDE1OC41LTY2cTkyIDAgMTU4IDY2dDY2IDE1OHoiLz48L3N2Zz4=);-webkit-animation:spin 2s infinite linear;animation:spin 2s infinite linear}@-webkit-keyframes spin{0%{box-sizing:border-box;-webkit-transform:rotate(0deg);transform:rotate(0deg)}to{box-sizing:border-box;-webkit-transform:rotate(359.9deg);transform:rotate(359.9deg)}}@keyframes spin{0%{box-sizing:border-box;-webkit-transform:rotate(0deg);transform:rotate(0deg)}to{box-sizing:border-box;-webkit-transform:rotate(359.9deg);transform:rotate(359.9deg)}}.gitter-chat-embed-action-bar{position:absolute;top:0;left:0;right:0;-webkit-box-pack:end;-ms-flex-pack:end;justify-content:flex-end;padding-bottom:.7em;background:-webkit-linear-gradient(top,#fff,#fff 50%,hsla(0,0%,100%,0));background:linear-gradient(180deg,#fff 0,#fff 50%,hsla(0,0%,100%,0))}.gitter-chat-embed-action-bar,.gitter-chat-embed-action-bar-item{box-sizing:border-box;display:-webkit-box;display:-ms-flexbox;display:flex}.gitter-chat-embed-action-bar-item{-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;width:40px;height:40px;padding-left:0;padding-right:0;opacity:.65;background:none;background-position:50%;background-repeat:no-repeat;background-size:22px 22px;border:0;outline:none;cursor:pointer;cursor:hand;-webkit-transition:all .2s ease;transition:all .2s ease}.gitter-chat-embed-action-bar-item:focus,.gitter-chat-embed-action-bar-item:hover{box-sizing:border-box;opacity:1}.gitter-chat-embed-action-bar-item:active{box-sizing:border-box;-webkit-filter:hue-rotate(80deg) saturate(150);filter:hue-rotate(80deg) saturate(150)}.gitter-chat-embed-action-bar-item-pop-out{box-sizing:border-box;margin-right:-4px;background-image:url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAyMDAgMTcxLjQyOSIgZmlsbD0iIzNhMzEzMyI+PHBhdGggZD0iTTE1Ny4xNDMsMTAzLjU3MXYzNS43MTRjMCw4Ljg1NC0zLjE0NCwxNi40MjYtOS40MzEsMjIuNzEzcy0xMy44NTgsOS40MzEtMjIuNzEyLDkuNDMxSDMyLjE0MyBjLTguODU0LDAtMTYuNDI1LTMuMTQ0LTIyLjcxMi05LjQzMVMwLDE0OC4xNCwwLDEzOS4yODVWNDYuNDI5YzAtOC44NTQsMy4xNDQtMTYuNDI1LDkuNDMxLTIyLjcxMiBjNi4yODctNi4yODcsMTMuODU4LTkuNDMxLDIyLjcxMi05LjQzMWg3OC41NzJjMS4wNDEsMCwxLjg5NiwwLjMzNSwyLjU2NiwxLjAwNGMwLjY3LDAuNjcsMS4wMDQsMS41MjUsMS4wMDQsMi41NjdWMjUgYzAsMS4wNDItMC4zMzQsMS44OTctMS4wMDQsMi41NjdjLTAuNjcsMC42Ny0xLjUyNSwxLjAwNC0yLjU2NiwxLjAwNEgzMi4xNDNjLTQuOTExLDAtOS4xMTUsMS43NDktMTIuNjEyLDUuMjQ2IHMtNS4yNDYsNy43MDEtNS4yNDYsMTIuNjEydjkyLjg1NmMwLDQuOTExLDEuNzQ5LDkuMTE1LDUuMjQ2LDEyLjYxMnM3LjcwMSw1LjI0NSwxMi42MTIsNS4yNDVIMTI1YzQuOTEsMCw5LjExNS0xLjc0OCwxMi42MTEtNS4yNDUgYzMuNDk3LTMuNDk3LDUuMjQ2LTcuNzAxLDUuMjQ2LTEyLjYxMnYtMzUuNzE0YzAtMS4wNDIsMC4zMzQtMS44OTcsMS4wMDQtMi41NjdjMC42Ny0wLjY2OSwxLjUyNS0xLjAwNCwyLjU2Ny0xLjAwNGg3LjE0MyBjMS4wNDIsMCwxLjg5NywwLjMzNSwyLjU2NywxLjAwNEMxNTYuODA5LDEwMS42NzQsMTU3LjE0MywxMDIuNTI5LDE1Ny4xNDMsMTAzLjU3MXogTTIwMCw3LjE0M3Y1Ny4xNDMgYzAsMS45MzUtMC43MDcsMy42MDktMi4xMjEsNS4wMjJjLTEuNDEzLDEuNDE0LTMuMDg4LDIuMTIxLTUuMDIxLDIuMTIxYy0xLjkzNSwwLTMuNjA5LTAuNzA3LTUuMDIyLTIuMTIxbC0xOS42NDQtMTkuNjQzIGwtNzIuNzY3LDcyLjc2OWMtMC43NDQsMC43NDQtMS42LDEuMTE1LTIuNTY3LDEuMTE1cy0xLjgyMy0wLjM3MS0yLjU2Ny0xLjExNUw3Ny41NjcsMTA5LjcxYy0wLjc0NC0wLjc0NC0xLjExNi0xLjYtMS4xMTYtMi41NjcgYzAtMC45NjcsMC4zNzItMS44MjIsMS4xMTYtMi41NjZsNzIuNzY4LTcyLjc2OGwtMTkuNjQ0LTE5LjY0M2MtMS40MTMtMS40MTQtMi4xMi0zLjA4OC0yLjEyLTUuMDIyYzAtMS45MzUsMC43MDctMy42MDksMi4xMi01LjAyMiBDMTMyLjEwNSwwLjcwNywxMzMuNzc5LDAsMTM1LjcxNSwwaDU3LjE0M2MxLjkzNCwwLDMuNjA4LDAuNzA3LDUuMDIxLDIuMTIxQzE5OS4yOTMsMy41MzQsMjAwLDUuMjA4LDIwMCw3LjE0M3oiLz48L3N2Zz4=)}.gitter-chat-embed-action-bar-item-collapse-chat{box-sizing:border-box;background-image:url(data:image/svg+xml;base64,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)}.gitter-open-chat-button{z-index:100;position:fixed;bottom:0;right:10px;padding:1em 3em;background-color:#36bc98;border:0;border-top-left-radius:.5em;border-top-right-radius:.5em;font-family:sans-serif;font-size:12px;letter-spacing:1px;text-transform:uppercase;text-align:center;text-decoration:none;cursor:pointer;cursor:hand;-webkit-transition:all .3s ease;transition:all .3s ease}.gitter-open-chat-button,.gitter-open-chat-button:visited{box-sizing:border-box;color:#fff}.gitter-open-chat-button:focus,.gitter-open-chat-button:hover{box-sizing:border-box;background-color:#3ea07f;color:#fff}.gitter-open-chat-button:focus{box-sizing:border-box;box-shadow:0 0 8px rgba(62,160,127,.6);outline:none}.gitter-open-chat-button:active{box-sizing:border-box;color:#eee}.gitter-open-chat-button.is-collapsed{box-sizing:border-box;-webkit-transform:translateY(120%);transform:translateY(120%)}</style><link href="https://gmpg.org/xfn/11" rel="profile">

 
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">
<meta name="description" content="Open-Source Deep-Learning Software for Java and Scala on Hadoop and Spark">
<meta name="author" content="Chris Nicholson, Adam Gibson">
<title>
Convolutional Networks in Java - Deeplearning4j: Open-source, Distributed Deep Learning for the JVM
</title>
 
<link href="./Convolutional Networks in Java - Deeplearning4j_ Open-source, Distributed Deep Learning for the JVM_files/theDocs.all.min.css" rel="stylesheet">
<link href="./Convolutional Networks in Java - Deeplearning4j_ Open-source, Distributed Deep Learning for the JVM_files/skin-dark.css" rel="stylesheet">
 
<link href="./Convolutional Networks in Java - Deeplearning4j_ Open-source, Distributed Deep Learning for the JVM_files/css" rel="stylesheet" type="text/css">
 
<link rel="apple-touch-icon-precomposed" sizes="144x144" href="https://deeplearning4j.org/assets/themes/thedocs/img/apple-touch-icon-precomposed.png">
<link rel="shortcut icon" href="https://deeplearning4j.org/assets/themes/thedocs/img/favicon.ico">
 
<link rel="alternate" type="application/rss+xml" title="RSS" href="https://deeplearning4j.org/atom.xml">
 
<script async="" defer="" src="./Convolutional Networks in Java - Deeplearning4j_ Open-source, Distributed Deep Learning for the JVM_files/buttons.js"></script>
 
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-48811288-1', 'auto');
  ga('require', 'linkid', 'linkid.js');
  ga('send', 'pageview');
  ga('require', 'displayfeatures');
  </script>
 
 
<script type="text/javascript">
  setTimeout(function(){var a=document.createElement("script");
  var b=document.getElementsByTagName("script")[0];
  a.src=document.location.protocol+"//script.crazyegg.com/pages/scripts/0025/5605.js?"+Math.floor(new Date().getTime()/3600000);
  a.async=true;a.type="text/javascript";b.parentNode.insertBefore(a,b)}, 1);
  </script>
 
 
<script type="text/javascript">
    (function(d,s,i,r) {
      if (d.getElementById(i)){return;}
      var n=d.createElement(s),e=d.getElementsByTagName(s)[0];
      n.id=i;n.src='//js.hs-analytics.net/analytics/'+(Math.ceil(new Date()/r)*r)+'/2179705.js';
      e.parentNode.insertBefore(n, e);
    })(document,"script","hs-analytics",300000);
  </script>
 
 
<script>
  window.upvertSettings = {
    id: '582e00a3ed01d8001138f5b6',
    launcherPosition: 'hidden'
  };
</script>
<script>!function(a,b,c,d){if(a.Upvert=a.Upvert||{show:function(){a.upvertSettings.showOnLoad=!0},hide:function(){}},!b.getElementById(d)&&!a.Upvert.isLoaded){var e=b.createElement(c),f=b.getElementsByTagName(c)[0];e.id=d,e.src="https://static.upvert.io/loader.js",e.type="text/javascript",e.async=!0,f.parentNode.insertBefore(e,f)}}(window,document,"script","upvert-loader");</script>
 
<style type="text/css">.upvertOpen{overflow:hidden !important}@media (max-width: 767px){.upvertOpen{overflow:hidden !important;position:fixed !important;width:100% !important;height:100% !important}}.upvertLauncher,.upvertBeacon{z-index:2147483646;display:none;opacity:0;position:fixed;overflow:hidden;width:60px;height:60px;background-color:transparent;color:#fff;border:0 none transparent;border-radius:50%;box-shadow:0 0 40px rgba(0,0,0,0.08);transition:opacity 80ms ease-in-out}.upvertLauncher,.upvertBeacon{display:none !important}.upvertWidget,.upvertOverlay{z-index:2147483647;display:none;opacity:0;position:fixed;overflow:hidden;border:0 none transparent;border-radius:8px;background-color:transparent;box-shadow:0 4px 40px rgba(0,0,0,0.16);transition:opacity 80ms ease-in-out}.upvertWidget,.upvertOverlay{width:360px;height:calc(100% - 100px - 100px);min-height:280px;top:100px;right:20px;bottom:100px;left:initial}@media (max-width: 767px){.upvertWidget,.upvertOverlay{width:100%;height:100%;max-width:100%;max-height:100%;border-radius:0;box-shadow:none;top:0;right:0;bottom:0;left:0}}</style><style type="text/css">.hs-button{background-color: transparent; border: 1px solid transparent; border-radius: 3px; color: #2196f3; border-color: #2196f3; margin-top: 10px;} .hs-input {.width: 100%; padding: 0px 10px; border: 1px solid #e7e7e7; transition: .5s ease;} .hs-form-required{display:none;} .hs-error-msgs{font-size: 15px; color: #FF0000;}.pika-single{z-index:9999;display:block;position:relative;color:#333;background:#fff;border:1px solid #ccc;border-bottom-color:#bbb;font-family:"Helvetica Neue",Helvetica,Arial,sans-serif}.pika-single.is-hidden{display:none}.pika-single.is-bound{position:absolute;box-shadow:0 5px 15px -5px rgba(0,0,0,0.5)}.pika-single{*zoom:1}.pika-single:before,.pika-single:after{content:" ";display:table}.pika-single:after{clear:both}.pika-lendar{float:left;width:240px;margin:8px}.pika-title{position:relative;text-align:center}.pika-title select{cursor:pointer;position:absolute;z-index:9998;margin:0;left:0;top:5px;filter:alpha(opacity=0);opacity:0}.pika-label{display:inline-block;*display:inline;position:relative;z-index:9999;overflow:hidden;margin:0;padding:5px 3px;font-size:14px;line-height:20px;font-weight:bold;background-color:#fff}.pika-prev,.pika-next{display:block;cursor:pointer;position:relative;outline:none;border:0;padding:0;width:20px;height:30px;text-indent:20px;white-space:nowrap;overflow:hidden;background-color:transparent;background-position:center center;background-repeat:no-repeat;background-size:75% 75%;opacity:0.5;*position:absolute;*top:0}.pika-prev:hover,.pika-next:hover{opacity:1}.pika-prev.is-disabled,.pika-next.is-disabled{cursor:default;opacity:0.2}.pika-prev,.is-rtl .pika-next{float:left;background-image:url("data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAeCAYAAAAsEj5rAAAAUklEQVR42u3VMQoAIBADQf8Pgj+OD9hG2CtONJB2ymQkKe0HbwAP0xucDiQWARITIDEBEnMgMQ8S8+AqBIl6kKgHiXqQqAeJepBo/z38J/U0uAHlaBkBl9I4GwAAAABJRU5ErkJggg==");*left:0}.pika-next,.is-rtl .pika-prev{float:right;background-image:url("data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAeCAYAAAAsEj5rAAAAU0lEQVR42u3VOwoAMAgE0dwfAnNjU26bYkBCFGwfiL9VVWoO+BJ4Gf3gtsEKKoFBNTCoCAYVwaAiGNQGMUHMkjGbgjk2mIONuXo0nC8XnCf1JXgArVIZAQh5TKYAAAAASUVORK5CYII=");*right:0}.pika-select{display:inline-block;*display:inline}.pika-table{width:100%;border-collapse:collapse;border-spacing:0;border:0}.pika-table th,.pika-table td{width:14.28571%;padding:0}.pika-table th{color:#999;font-size:12px;line-height:25px;font-weight:bold;text-align:center}.pika-table abbr{border-bottom:none;cursor:help}.pika-button{cursor:pointer;display:block;-moz-box-sizing:border-box;box-sizing:border-box;outline:none;border:0;margin:0;width:100%;padding:5px;color:#666;font-size:12px;line-height:15px;text-align:right;background:#f5f5f5}.is-today .pika-button{color:#3af;font-weight:bold}.is-selected .pika-button{color:#fff;font-weight:bold;background:#3af;box-shadow:inset 0 1px 3px #178fe5;border-radius:3px}.is-disabled .pika-button{pointer-events:none;cursor:default;color:#999;opacity:0.3}.pika-button:hover{color:#fff !important;background:#ff8000 !important;box-shadow:none !important;border-radius:3px !important}.pika-week{font-size:11px;color:#999}.hs-form fieldset{border:0;padding:0;margin:0;max-width:500px}.hs-form fieldset.form-columns-1 .hs-input{width:95%}.hs-form fieldset.form-columns-1 .input{margin-right:8px}.hs-form fieldset.form-columns-1 input[type="checkbox"],.hs-form fieldset.form-columns-1 input[type="radio"]{width:auto}.hs-form fieldset.form-columns-2 .hs-form-field{width:50%;float:left}.hs-form fieldset.form-columns-2 .input{margin-right:8px}.hs-form fieldset.form-columns-3 .hs-form-field{width:32.7%;float:left}.hs-form fieldset.form-columns-3 .input{margin-right:8px}.hs-form label.hs-hidden{visibility:hidden}.hsformerror{margin:0 0 2px;padding:2px 6px;height:auto;background-color:#fdd2d0;font-size:11px;border:1px solid #fcb3af;padding:4px 16px 4px 10px;color:#000;display:none;background-image:-webkit-gradient(linear, 50% 0%, 50% 100%, color-stop(0%, #fefefe), color-stop(100%, #fdd2d0));background-image:-webkit-linear-gradient(#fefefe, #fdd2d0);background-image:-moz-linear-gradient(#fefefe, #fdd2d0);background-image:-o-linear-gradient(#fefefe, #fdd2d0);background-image:linear-gradient(#fefefe,#fdd2d0);-webkit-border-radius:4px;-moz-border-radius:4px;-ms-border-radius:4px;-o-border-radius:4px;border-radius:4px;-webkit-box-shadow:0 0 6px #ddd;-moz-box-shadow:0 0 6px #ddd;box-shadow:0 0 6px #ddd;z-index:99999}.hsformerror em{border:10px solid;border-color:#fdd2d0 transparent transparent;bottom:-17px;display:block;height:0;left:60px;position:absolute;width:0}.hsformerror p{font-family:Lucida Grande,Lucida Sans Unicode,bitstream vera sans,trebuchet ms,verdana,sans-serif;margin:0;float:left;margin-right:8px}.hsformerror:hover{cursor:default}.hsformerror .close-form-error{float:right;display:inline;top:3px;position:absolute;font-family:Verdana !important;color:#b17c79 !important;cursor:pointer !important;font-size:11px !important;font-weight:normal !important}.hsformerror .close-form-error:hover{color:#cc8884}@media (max-width: 400px), (min-device-width: 320px) and (max-device-width: 480px){form.hs-form .form-columns-2 .hs-form-field,form.hs-form .form-columns-3 .hs-form-field{float:none;width:100%}form.hs-form .form-columns-2 .hs-form-field .hs-input,form.hs-form .form-columns-3 .hs-form-field .hs-input{width:95%}}</style><style id="fit-vids-style">.fluid-width-video-wrapper{width:100%;position:relative;padding:0;}.fluid-width-video-wrapper iframe,.fluid-width-video-wrapper object,.fluid-width-video-wrapper embed {position:absolute;top:0;left:0;width:100%;height:100%;}</style><link rel="stylesheet" href="blob:https://deeplearning4j.org/cd10a553-0f76-428a-b2f9-77eb9c05e170"><link rel="stylesheet" href="blob:https://deeplearning4j.org/2c81d082-6d0e-4109-9f4a-0eaf91bdc2f3"></head>
<body>
 
<style>li.subscribe-form{padding:2px 20px!important;}.hs-richtext{margin-bottom:-30px;}.hs-button{background-color:#2196f3;border-color:#2196f3;color:#fff;margin-top:10px;}</style>
 
 
<header class="site-header navbar-fullwidth">
 
<nav class="navbar navbar-default">
<div class="container">
 
<div class="navbar-header">
<button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#navbar" aria-expanded="true" aria-controls="navbar">
<span class="glyphicon glyphicon-option-vertical"></span>
</button>
<button type="button" class="navbar-toggle for-sidebar" data-toggle="offcanvas">
<span class="icon-bar"></span>
<span class="icon-bar"></span>
<span class="icon-bar"></span>
</button>
<a class="navbar-brand" href="https://deeplearning4j.org/index.html"><span class="force-middle"></span><img src="./Convolutional Networks in Java - Deeplearning4j_ Open-source, Distributed Deep Learning for the JVM_files/DL4J-2.png" alt="Deeplearning4j" height="25px"></a>
</div>
 
 
<div id="navbar" class="navbar-collapse collapse" aria-expanded="true" role="banner">
<ul class="nav navbar-nav navbar-right">
<li class="hero"><a href="https://deeplearning4j.org/quickstart">Quickstart</a></li>
<li><a href="https://deeplearning4j.org/documentation">Documentation</a></li>
<li><a href="https://deeplearning4j.org/gpu">GPUs</a></li>
<li><a href="https://deeplearning4j.org/spark">Spark</a></li>
<li><a href="https://deeplearning4j.org/word2vec">Word2Vec</a></li>
<li><a href="https://deeplearning4j.org/about">About</a></li>
<li><a href="javascript:Upvert.show();">FAQ</a></li>
</ul>
</div>
<div class="github-ribbon">
<a href="https://github.com/deeplearning4j/deeplearning4j"><img style="position: absolute; top: 0; right: 0; border: 0;" src="./Convolutional Networks in Java - Deeplearning4j_ Open-source, Distributed Deep Learning for the JVM_files/68747470733a2f2f73332e616d617a6f6e6177732e636f6d2f6769746875622f726962626f6e732f666f726b6d655f72696768745f677265656e5f3030373230302e706e67" alt="Fork me on GitHub" data-canonical-src="https://s3.amazonaws.com/github/ribbons/forkme_right_green_007200.png"></a>
</div>
 
</div>
</nav>
 
</header>
 
 
<aside class="sidebar sidebar-boxed sidebar-dark">
<a class="sidebar-brand" href="https://deeplearning4j.org/index.html"><img src="./Convolutional Networks in Java - Deeplearning4j_ Open-source, Distributed Deep Learning for the JVM_files/DL4J-LOGO-2.png" alt="Deeplearning4j"></a>
<ul class="sidenav dropable sticky" style="height: 494px; position: static;">
<li><a href="https://www.amazon.com/Deep-Learning-Practitioners-Adam-Gibson/dp/1491914254" target="_blank">Deep Learning Textbook</a></li>
<li>
<a href="https://deeplearning4j.org/convolutionalnets#" class="has-child">Getting Started</a>
<ul>
<li><a href="https://deeplearning4j.org/quickstart">Quickstart: Running DL4J</a></li>
<li><a href="https://deeplearning4j.org/gettingstarted">Comprehensive Setup Guide</a></li>
<li><a href="https://deeplearning4j.org/buildinglocally">Build Locally From Master</a></li>
<li><a href="https://deeplearning4j.org/maven">Use the Maven Build Tool</a></li>
<li><a href="https://deeplearning4j.org/buildtools">Configure DL4J in Ivy, Gradle, SBT etc.</a></li>
<li><a href="http://nd4j.org/gpu_native_backends.html">Swap CPUs for GPUs</a></li>
</ul>
</li>
<li>
<a href="https://deeplearning4j.org/convolutionalnets#" class="has-child">Tutorials</a>
<ul>
<li><a href="https://deeplearning4j.org/tutorials">Deep Learning Tutorial Index</a></li>
<li><a href="https://deeplearning4j.org/mnist-for-beginners">MNIST for Beginners</a></li>
<li><a href="https://deeplearning4j.org/usingrnns">Using Recurrent Nets in DL4J</a></li>
<li><a href="http://nd4j.org/userguide">Use ND4J for Scientific Computing</a></li>
<li><a href="https://deeplearning4j.org/datavec">DataVec: Vectorization and Preprocessing for Machine Learning</a></li>
<li><a href="https://deeplearning4j.org/updater">Neural Net Updaters: SGD, Adam, Adagrad, Adadelta, RMSProp</a></li>
<li><a href="https://deeplearning4j.org/welldressed-recommendation-engine">Build a Recommendation Engine With DL4J</a></li>
</ul>
</li>
<li>
<a href="https://deeplearning4j.org/convolutionalnets#" class="has-child">Introduction to Deep Learning</a>
<ul>
<li><a href="https://deeplearning4j.org/neuralnet-overview">Introduction to Neural Networks</a></li>
<li><a href="https://deeplearning4j.org/questions">Questions to Ask When Applying DL</a></li>
<li><a href="https://deeplearning4j.org/deeplearningforbeginners.html">Deep Learning for Beginners</a></li>
<li><a href="https://deeplearning4j.org/use_cases">Use Cases</a></li>
<li><a href="https://deeplearning4j.org/accuracy">Deep Learning's Accuracy</a></li>
<li><a href="https://deeplearning4j.org/ai-machinelearning-deeplearning">AI, Machine Learning and Deep Learning</a></li>
<li><a href="https://deeplearning4j.org/data-for-deep-learning.html">The Data You Need For Deep Learning</a></li>
<li><a href="https://deeplearning4j.org/multinetwork">Multilayer Neural Nets</a></li>
<li><a href="https://deeplearning4j.org/neuralnetworktable">Choosing a Neural Network</a></li>
</ul>
</li>
<li>
<a href="https://deeplearning4j.org/convolutionalnets#" class="has-child">Neural Networks</a>
<ul>
<li><a href="https://deeplearning4j.org/lstm">Long Short-Term Memory Units</a></li>
<li><a href="https://deeplearning4j.org/convolutionalnets">Convolutional Nets for Image Processing</a></li>
<li><a href="https://deeplearning4j.org/recurrentnetwork">Recurrent Nets and LSTMs</a></li>
<li><a href="https://deeplearning4j.org/word2vec">Word2Vec: Neural Word Embeddings</a></li>
<li><a href="https://deeplearning4j.org/restrictedboltzmannmachine">Restricted Boltzmann Machines</a></li>
<li><a href="https://deeplearning4j.org/deepautoencoder">Deep AutoEncoder</a></li>
<li><a href="https://deeplearning4j.org/denoisingautoencoder">Denoising Autoencoders</a></li>
<li><a href="https://deeplearning4j.org/stackeddenoisingautoencoder">Stacked Denoising Autoencoders</a></li>
</ul>
</li>
<li>
<a href="https://deeplearning4j.org/convolutionalnets#" class="has-child">Data &amp; ETL</a>
<ul>
<li><a href="https://deeplearning4j.org/datavec">DataVec: ETL for ML</a></li>
<li><a href="https://deeplearning4j.org/data-sets-ml">Datasets and Machine Learning</a></li>
<li><a href="https://deeplearning4j.org/customdatasets">Custom Datasets</a></li>
<li><a href="https://deeplearning4j.org/csv-deep-learning">CSV Data Uploads</a></li>
<li><a href="https://deeplearning4j.org/opendata">Open Data</a></li>
<li><a href="https://deeplearning4j.org/image-data-pipeline.html#record">Build a Data Pipeline</a></li>
<li><a href="https://deeplearning4j.org/simple-image-load-transform">Customize an Image Pipeline</a></li>
<li><a href="https://deeplearning4j.org/datavecdoc/">DataVec Javadoc: DataVec Methods &amp; Classes for ETL</a></li>
</ul>
</li>
<li>
<a href="https://deeplearning4j.org/convolutionalnets#" class="has-child">Tuning &amp; Training</a>
<ul>
<li><a href="https://deeplearning4j.org/spark">Training Neural Networks with Apache Spark</a></li>
<li><a href="https://deeplearning4j.org/iterativereduce">Distributed Training: Iterative Reduce Defined</a></li>
<li><a href="https://deeplearning4j.org/visualization">Visualize, Monitor and Debug Network Learning</a></li>
<li><a href="https://deeplearning4j.org/troubleshootingneuralnets">Troubleshoot Training &amp; Select Network Hyperparameters</a></li>
<li><a href="https://deeplearning4j.org/earlystopping">Train Networks using Early Stopping</a></li>
<li><a href="https://deeplearning4j.org/output">Interpret Neural Net Output</a></li>
</ul>
</li>
<li>
<a href="https://deeplearning4j.org/convolutionalnets#" class="has-child">Deployment</a>
<ul>
<li><a href="https://deeplearning4j.org/spark-gpus">Running Deep Learning on Distributed GPUs With Spark</a></li>
<li><a href="https://deeplearning4j.org/model-zoo">Model Zoo: Pre-trained Models</a></li>
<li><a href="https://deeplearning4j.org/modelpersistence">Save and Load Models</a></li>
<li><a href="https://deeplearning4j.org/tsne-visualization">Visualize Data with t-SNE</a></li>
<li><a href="https://deeplearning4j.org/linear-regression">Perform Regression With Neural Nets</a></li>
<li><a href="https://deeplearning4j.org/usingrnns">Use Recurrent Networks in DL4J</a></li>
<li><a href="https://deeplearning4j.org/compgraph">Build Complex Network Architectures with Computation Graph</a></li>
</ul>
</li>
<li>
<a href="https://deeplearning4j.org/convolutionalnets#" class="has-child">Open-Source Community</a>
<ul>
<li><a href="https://deeplearning4j.org/devguide">Contribute to DL4J (Developer Guide)</a></li>
<li><a href="https://deeplearning4j.org/architecture">Architecture</a></li>
<li><a href="https://deeplearning4j.org/features">Features</a></li>
<li><a href="https://deeplearning4j.org/roadmap">Roadmap</a></li>
<li><a href="https://deeplearning4j.org/releasenotes">Latest Release Notes</a></li>
<li><a href="https://deeplearning4j.org/doc">Javadoc: DL4J Methods and Classes</a></li>
</ul>
</li>
<li>
<a href="https://deeplearning4j.org/convolutionalnets#" class="has-child">Natural Language Processing</a>
<ul>
<li><a href="https://deeplearning4j.org/nlp">DL4J's NLP Framework</a></li>
<li><a href="https://deeplearning4j.org/word2vec">Word2vec for Java and Scala</a></li>
<li><a href="https://deeplearning4j.org/doc2vec">Doc2vec for Java and Scala</a></li>
<li><a href="https://deeplearning4j.org/textanalysis">Textual Analysis and DL</a></li>
<li><a href="https://deeplearning4j.org/bagofwords-tf-idf">Bag of Words</a></li>
<li><a href="https://deeplearning4j.org/sentenceiterator">Sentence and Document Segmentation</a></li>
<li><a href="https://deeplearning4j.org/tokenization">Tokenization</a></li>
<li><a href="https://deeplearning4j.org/vocabcache">Vocab Cache</a></li>
</ul>
</li>
<li>
<a href="https://deeplearning4j.org/convolutionalnets#" class="has-child">ND4J: Numpy for the JVM</a>
<ul>
<li><a href="http://nd4j.org/backend.html">ND4J Backends: Hardware Acceleration on CPUs and GPUs</a></li>
<li><a href="http://nd4j.org/userguide">ND4J User Guide</a></li>
<li><a href="http://nd4j.org/doc/">ND4J Javadoc</a></li>
</ul>
</li>
<li>
<a href="https://deeplearning4j.org/convolutionalnets#" class="has-child">Resources</a>
<ul>
<li><a href="https://deeplearning4j.org/eigenvector">Eigenvectors, PCA, Covariance and Entropy</a></li>
<li><a href="https://deeplearning4j.org/thoughtvectors">Thought Vectors, AI and NLP</a></li>
<li><a href="https://deeplearning4j.org/markovchainmontecarlo">Monte Carlo, Markov Chains and Deep Learning</a></li>
<li><a href="https://deeplearning4j.org/unsupervised-learning">Unsupervised Learning: Use Cases</a></li>
<li><a href="https://deeplearning4j.org/reinforcementlearning">DL and Reinforcement Learning</a></li>
<li><a href="https://deeplearning4j.org/scala">Scala, Spark and Deep Learning</a></li>
<li><a href="https://deeplearning4j.org/compare-dl4j-torch7-pylearn">DL4J, Torch7, Theano and Caffe</a></li>
<li><a href="https://deeplearning4j.org/glossary">Glossary of Terms for Deep Learning and Neural Nets</a></li>
<li><a href="https://deeplearning4j.org/deeplearningpapers">Free Online Courses, Tutorials and Papers</a></li>
<li><a href="https://deeplearning4j.org/deeplearningtranslated">Deep Learning in Other Languages</a></li>
</ul>
</li>
<li>
<a href="https://deeplearning4j.org/convolutionalnets#" class="has-child">Other Languages</a>
<ul>
<li><a href="https://deeplearning4j.org/cn/index">中文</a></li>
<li><a href="https://deeplearning4j.org/ja-index">日本語</a></li>
<li><a href="https://deeplearning4j.org/kr-index">한글</a></li>
</ul>
</li>
<li class="subscribe-form">
 
<!--[if lte IE 8]>
      <script charset="utf-8" type="text/javascript" src="//js.hsforms.net/forms/v2-legacy.js"></script>
      <![endif]-->
<script charset="utf-8" type="text/javascript" src="./Convolutional Networks in Java - Deeplearning4j_ Open-source, Distributed Deep Learning for the JVM_files/v2.js"></script>
<script>
        hbspt.forms.create({
          css: '.hs-button{background-color: transparent; border: 1px solid transparent; border-radius: 3px; color: #2196f3; border-color: #2196f3; margin-top: 10px;} .hs-input {.width: 100%; padding: 0px 10px; border: 1px solid #e7e7e7; transition: .5s ease;} .hs-form-required{display:none;} .hs-error-msgs{font-size: 15px; color: #FF0000;}',
          portalId: '2179705',
          formId: 'fe8cb1a1-6604-4bea-b578-29ad9c6377e6'
        });
      </script><div class="hbspt-form" id="hbspt-form-1481413173021"><form novalidate="" accept-charset="UTF-8" action="https://forms.hubspot.com/uploads/form/v2/2179705/fe8cb1a1-6604-4bea-b578-29ad9c6377e6" enctype="multipart/form-data" id="hsForm_fe8cb1a1-6604-4bea-b578-29ad9c6377e6" method="POST" class="hs-form stacked" data-form-id="fe8cb1a1-6604-4bea-b578-29ad9c6377e6" data-portal-id="2179705" data-reactid=".hbspt-forms-0"><div data-reactid=".hbspt-forms-0.0:$0"><div class="hs-richtext" data-reactid=".hbspt-forms-0.0:$0.0"><h6>Subscribe to our mailing list</h6></div><div class="hs_email field hs-form-field" data-reactid=".hbspt-forms-0.0:$0.$email"><label class="" placeholder="Enter your " for="email-fe8cb1a1-6604-4bea-b578-29ad9c6377e6" data-reactid=".hbspt-forms-0.0:$0.$email.0"><span data-reactid=".hbspt-forms-0.0:$0.$email.0.0"></span><span class="hs-form-required" data-reactid=".hbspt-forms-0.0:$0.$email.0.1">*</span></label><legend class="hs-field-desc" style="display:none;" data-reactid=".hbspt-forms-0.0:$0.$email.1"></legend><div class="input" data-reactid=".hbspt-forms-0.0:$0.$email.$email"><input id="email-fe8cb1a1-6604-4bea-b578-29ad9c6377e6" class="hs-input" type="email" name="email" required="" placeholder="Your email..." value="" data-reactid=".hbspt-forms-0.0:$0.$email.$email.0"></div></div></div><div data-reactid=".hbspt-forms-0.0:$1"><div class="hs_lifecyclestage field hs-form-field" style="display:none;" data-reactid=".hbspt-forms-0.0:$1.$lifecyclestage"><label class="" placeholder="Enter your Lifecycle Stage" for="lifecyclestage-fe8cb1a1-6604-4bea-b578-29ad9c6377e6" data-reactid=".hbspt-forms-0.0:$1.$lifecyclestage.0"><span data-reactid=".hbspt-forms-0.0:$1.$lifecyclestage.0.0">Lifecycle Stage</span></label><legend class="hs-field-desc" style="display:none;" data-reactid=".hbspt-forms-0.0:$1.$lifecyclestage.1"></legend><div class="input" data-reactid=".hbspt-forms-0.0:$1.$lifecyclestage.$lifecyclestage"><input name="lifecyclestage" class="hs-input" type="hidden" value="subscriber" data-reactid=".hbspt-forms-0.0:$1.$lifecyclestage.$lifecyclestage.0"></div></div></div><div class="hs_submit" data-reactid=".hbspt-forms-0.2"><div class="hs-field-desc" style="display:none;" data-reactid=".hbspt-forms-0.2.0"></div><div class="actions" data-reactid=".hbspt-forms-0.2.1"><input type="submit" value="Keep me updated!" class="hs-button primary large" data-reactid=".hbspt-forms-0.2.1.0"></div></div><input name="hs_context" type="hidden" value="{&quot;rumScriptExecuteTime&quot;:348.285,&quot;rumServiceResponseTime&quot;:1435.4950000000001,&quot;rumFormRenderTime&quot;:158.19000000000005,&quot;rumTotalRequestTime&quot;:155.47000000000003,&quot;css&quot;:&quot;&quot;,&quot;pageUrl&quot;:&quot;https://deeplearning4j.org/convolutionalnets&quot;,&quot;pageTitle&quot;:&quot;Convolutional Networks in Java - Deeplearning4j: Open-source, Distributed Deep Learning for the JVM&quot;,&quot;source&quot;:&quot;FormsNext-static-1.399&quot;,&quot;isHostedOnHubspot&quot;:false,&quot;timestamp&quot;:1481413173981,&quot;userAgent&quot;:&quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2883.75 Safari/537.36&quot;,&quot;referrer&quot;:&quot;https://deeplearning4j.org/restrictedboltzmannmachine.html&quot;,&quot;hutk&quot;:&quot;a778a5c844b06db899d0b88c76db3380&quot;,&quot;originalEmbedContext&quot;:{&quot;css&quot;:&quot;.hs-button{background-color: transparent; border: 1px solid transparent; border-radius: 3px; color: #2196f3; border-color: #2196f3; margin-top: 10px;} .hs-input {.width: 100%; padding: 0px 10px; border: 1px solid #e7e7e7; transition: .5s ease;} .hs-form-required{display:none;} .hs-error-msgs{font-size: 15px; color: #FF0000;}&quot;,&quot;portalId&quot;:&quot;2179705&quot;,&quot;formId&quot;:&quot;fe8cb1a1-6604-4bea-b578-29ad9c6377e6&quot;,&quot;target&quot;:&quot;#hbspt-form-1481413173021&quot;},&quot;recentFieldsCookie&quot;:{},&quot;boolCheckBoxFields&quot;:&quot;&quot;,&quot;dateFields&quot;:&quot;&quot;,&quot;smartFields&quot;:{},&quot;urlParams&quot;:{},&quot;formValidity&quot;:{},&quot;correlationId&quot;:&quot;e427d5d7-90d9-42be-b594-30d788e35a7d&quot;,&quot;disableCookieSubmission&quot;:false}" data-reactid=".hbspt-forms-0.3"></form></div>
 
</li>
</ul>
</aside><div id="upvert-widget" class="upvertWidget"><iframe allowfullscreen="" frameborder="0" scrolling="0" src="./Convolutional Networks in Java - Deeplearning4j_ Open-source, Distributed Deep Learning for the JVM_files/saved_resource.html" style="width: 100%; height: 100%;"></iframe></div>
 
<main class="container-fluid">
<div class="row">
 
<article class="main-content" role="main">
<h1 id="convolutional-networks"><a href="https://deeplearning4j.org/convolutionalnets#convolutional-networks">Convolutional Networks</a></h1>
<p>Contents</p>
<ul>
<li><a href="https://deeplearning4j.org/convolutionalnets#intro">Convolutional Net Introduction</a></li>
<li><a href="https://deeplearning4j.org/convolutionalnets#tensors">Images Are 4-D Tensors?</a></li>
<li><a href="https://deeplearning4j.org/convolutionalnets#define">ConvNet Definition</a></li>
<li><a href="https://deeplearning4j.org/convolutionalnets#work">How Convolutional Nets Work</a></li>
<li><a href="https://deeplearning4j.org/convolutionalnets#max">Maxpooling/Downsampling</a></li>
<li><a href="https://deeplearning4j.org/convolutionalnets#code">DL4J Code Sample</a></li>
<li><a href="https://deeplearning4j.org/convolutionalnets#resource">Other Resources</a></li>
</ul>
<h2 id="a-nameintroconvolutional-net-introductiona"><a href="https://deeplearning4j.org/convolutionalnets#a-nameintroconvolutional-net-introductiona"></a><a name="intro">Convolutional Net Introduction</a></h2>
<p>Convolutional nets can be used to classify images (name what they see), cluster them by similarity (photo search), and perform object recognition within scenes. They can identify faces, individuals, street signs, eggplants, platypuses and many other aspects of visual data.</p>
<p>Convolutional nets overlap with text analysis via optical character recognition (OCR), where the images are symbols to be transcribed, and they can also be applied to sound when it is represented visually.</p>
<p>The efficacy of convolutional nets (ConvNets or CNNs) in image recognition is one of the main reasons why the world has woken up to deep learning. They are powering major advances in machine vision, which has obvious applications for self-driving cars, robotics, drones, and treatments for the visually impaired.</p>
<p>Deeplearning4j wraps NVIDIA’s cuDNN and integrates with OpenCV. Our convolutional nets run on distributed GPUs using Spark, making them among the fastest in the world.</p>
<p align="center">
<a href="https://deeplearning4j.org/quickstart" type="button" class="btn btn-lg btn-success" onclick="ga(&#39;send&#39;, &#39;event&#39;, ‘quickstart&#39;, &#39;click&#39;);">GET STARTED WITH DEEPLEARNING4J</a>
</p>
<h2 id="a-nametensorsimages-are-4-d-tensorsa"><a href="https://deeplearning4j.org/convolutionalnets#a-nametensorsimages-are-4-d-tensorsa"></a><a name="tensors">Images Are 4-D Tensors?</a></h2>
<p>Convolutional nets ingest and process images as tensors, and tensors are matrices of numbers with additional dimensions.</p>
<p>They can be hard to visualize, so let’s approach them by analogy. A scalar is just a number, such as 7; a vector is a list of numbers (e.g., <code class="highlighter-rouge">[7,8,9]</code>); and a matrix is a rectangular grid of numbers occupying several rows and columns like a spreadsheet. Geometrically, if a scalar is a zero-dimensional point, then a vector is a one-dimensional line, a matrix is a two-dimensional plane, a stack of matrices is a three-dimensional cube, and when each element of those matrices has a stack of <em>feature maps</em> atttached to it, you enter the fourth dimension. For reference, here’s a 2 x 2 matrix:</p>
<div class="highlighter-rouge"><pre class="highlight"><span class="language-name"></span><a class="btn btn-sm btn-purple clipboard-copy" data-original-title="Copied!">Copy</a><code>[ 1, 2 ] 
[ 5, 8 ]</code></pre>
</div>
<p>A tensor encompasses the dimensions beyond that 2-D plane. You can easily picture a three-dimensional tensor, with the array of numbers arranged in a cube. Here’s a 2 x 3 x 2 tensor presented flatly (picture the bottom element of each 2-element array extending along the z-axis to intuitively grasp why it’s called a 3-dimensional array):</p>
<p><img src="./Convolutional Networks in Java - Deeplearning4j_ Open-source, Distributed Deep Learning for the JVM_files/tensor.png" alt="Alt text"></p>
<p>In code, the tensor above would appear like this: <code class="highlighter-rouge">[[[2,3],[3,5],[4,7]],[[3,4],[4,6],[5,8]]].</code> And here’s a visual:</p>
<p><img src="./Convolutional Networks in Java - Deeplearning4j_ Open-source, Distributed Deep Learning for the JVM_files/3d_matrix_cube.png" alt="Alt text"></p>
<p>In other words, tensors are formed by arrays nested within arrays, and that nesting can go on infinitely, accounting for an arbitrary number of dimensions far greater than what we can visualize spatially. A 4-D tensor would simply replace each of these scalars with an array nested one level deeper. Convolutional networks deal in 4-D tensors like the one below (notice the nested array).</p>
<p><img src="./Convolutional Networks in Java - Deeplearning4j_ Open-source, Distributed Deep Learning for the JVM_files/3d_matrix.png" alt="Alt text"></p>
<p>ND4J and Deeplearning4j use <code class="highlighter-rouge">NDArray</code> synonymously with tensor. A tensor’s dimensionality <code class="highlighter-rouge">(1,2,3…n)</code> is called its order; i.e. a fifth-order tensor would have five dimensions.</p>
<p>The width and height of an image are easily understood. The depth is necessary because of how colors are encoded. Red-Green-Blue (RGB) encoding, for example, produces an image three layers deep. Each layer is called a “channel”, and through convolution it produces a stack of feature maps (explained below), which exist in the fourth dimension, just down the street from time itself. (Features are just details of images, like a line or curve, that convolutional networks create maps of.)</p>
<p>So instead of thinking of images as two-dimensional areas, in convolutional nets they are treated as four-dimensional volumes. These ideas will be explored more thoroughly below.</p>
<h2 id="a-namedefinedefinitiona"><a href="https://deeplearning4j.org/convolutionalnets#a-namedefinedefinitiona"></a><a name="define">Definition</a></h2>
<p>From the Latin <em>convolvere</em>, “to convolve” means to roll together. For mathematical purposes, a convolution is the integral measuring how much two functions overlap as one passes over the other. Think of a convolution as a way of mixing two functions by multiplying them.</p>
 
<iframe src="./Convolutional Networks in Java - Deeplearning4j_ Open-source, Distributed Deep Learning for the JVM_files/convgaus.html" width="100%" height="260px;" style="border:none;"></iframe>
<p><em>Credit: <a href="http://mathworld.wolfram.com/">Mathworld</a>. “The green curve shows the convolution of the blue and red curves as a function of t, the position indicated by the vertical green line. The gray region indicates the product <code class="highlighter-rouge">g(tau)f(t-tau)</code> as a function of t, so its area as a function of t is precisely the convolution.”</em></p>
<p>Look at the tall, narrow bell curve standing in the middle of a graph. The integral is the area under that curve. Near it is a second bell curve that is shorter and wider, drifting slowly from the left side of the graph to the right. The product of those two functions’ overlap at each point along the x-axis is their <a href="http://mathworld.wolfram.com/Convolution.html">convolution</a>. So in a sense, the two functions are being “rolled together.”</p>
<p>With image analysis, the static, underlying function (the equivalent of the immobile bell curve) is the input image being analyzed, and the second, mobile function is known as the filter, because it picks up a signal or feature in the image. The two functions relate through multiplication. To visualize convolutions as matrices rather than as bell curves, please see <a href="https://cs231n.github.io/convolutional-networks/">Andrej Karpathy’s excellent animation</a> under the heading “Convolution Demo.”</p>
<p>The next thing to understand about convolutional nets is that they are passing <em>many</em> filters over a single image, each one picking up a different signal. At a fairly early layer, you could imagine them as passing a horizontal line filter, a vertical line filter, and a diagonal line filter to create a map of the edges in the image.</p>
<p>Convolutional networks take those filters, slices of the image’s feature space, and map them one by one; that is, they create a map of each place that feature occurs. By learning different portions of a feature space, convolutional nets allow for easily scalable and robust feature engineering.</p>
<p>(Note that convolutional nets analyze images differently than RBMs. While RBMs learn to reconstruct and identify the features of each image as a whole, convolutional nets learn images in pieces that we call feature maps.)</p>
<p>So convolutional networks perform a sort of search. Picture a small magnifying glass sliding left to right across a larger image, and recommencing at the left once it reaches the end of one pass (like typewriters do). That moving window is capable recognizing only one thing, say, a short vertical line. Three dark pixels stacked atop one another. It moves that vertical-line-recognizing filter over the actual pixels of the image, looking for matches.</p>
<p>Each time a match is found, it is mapped onto a feature space particular to that visual element. In that space, the location of each vertical line match is recorded, a bit like birdwatchers leave pins in a map to mark where they last saw a great blue heron. A convolutional net runs many, many searches over a single image – horizontal lines, diagonal ones, as many as there are visual elements to be sought.</p>
<p>Convolutional nets perform more operations on input than just convolutions themselves.</p>
<p>After a convolutional layer, input is passed through a nonlinear transform such as <em>tanh</em> or <em>rectified linear</em> unit, which will squash input values into a range between -1 and 1.</p>
<h2 id="a-nameworkhow-convolutional-networks-worka"><a href="https://deeplearning4j.org/convolutionalnets#a-nameworkhow-convolutional-networks-worka"></a><a name="work">How Convolutional Networks Work</a></h2>
<p>The first thing to know about convolutional networks is that they don’t perceive images like humans do. Therefore, you are going to have to think in a different way about what an image means as it is fed to and processed by a convolutional network.</p>
<p>Convolutional networks perceive images as volumes; i.e. three-dimensional objects, rather than flat canvases to be measured only by width and height. That’s because digital color images have a red-blue-green (RGB) encoding, mixing those three colors to produce the color spectrum humans perceive. A convolutional network ingests such images as three separate strata of color stacked one on top of the other.</p>
<p>So a convolutional network receives a normal color image as a rectangular box whose width and height are measured by the number of pixels along those dimensions, and whose depth is three layers deep, one for each letter in RGB. Those depth layers are referred to as <em>channels</em>.</p>
<p>As images move through a convolutional network, we will describe them in terms of input and output volumes, expressing them mathematically as matrices of multiple dimensions in this form: 30x30x3. From layer to layer, their dimensions change for reasons that will be explained below.</p>
<p>You will need to pay close attention to the precise measures of each dimension of the image volume, because they are the foundation of the linear algebra operations used to process images.</p>
<p>Now, for each pixel of an image, the intensity of R, G and B will be expressed by a number, and that number will be an element in one of the three, stacked two-dimensional matrices, which together form the image volume.</p>
<p>Those numbers are the initial, raw, sensory features being fed into the convolutional network, and the ConvNets purpose is to find which of those numbers are significant signals that actually help it classify images more accurately. (Just like other feedforward networks we have discussed.)</p>
<p>Rather than focus on one pixel at a time, a convolutional net takes in square patches of pixels and passes them through a <em>filter</em>. That filter is also a square matrix smaller than the image itself, and equal in size to the patch. It is also called a <em>kernel</em>, which will ring a bell for those familiar with support-vector machines, and the job of the filter is to find patterns in the pixels.</p>
<iframe src="./Convolutional Networks in Java - Deeplearning4j_ Open-source, Distributed Deep Learning for the JVM_files/index.html" width="100%" height="700px;" style="border:none;"></iframe>
<p><em>Credit for this excellent animation goes to <a href="https://cs231n.github.io/">Andrej Karpathy</a>.</em></p>
<p>Imagine two matrices. One is 30x30, and another is 3x3. That is, the filter covers one-tenth of one image channel’s surface area.</p>
<p>We are going to take the dot product of the filter with this patch of the image channel. If the two matrices have high values in the same positions, the dot product’s output will be high. If they don’t, it will be low. In this way, a single value – the output of the dot product – can tell us whether the pixel pattern in the underlying image matches the pixel pattern expressed by our filter.</p>
<p>Let’s imagine that our filter expresses a horizontal line, with high values along its second row and low values in the first and third rows. Now picture that we start in the upper lefthand corner of the underlying image, and we move the filter across the image step by step until it reaches the upper righthand corner. The size of the step is known as <em>stride</em>. You can move the filter to the right one column at a time, or you can choose to make larger steps.</p>
<p>At each step, you take another dot product, and you place the results of that dot product in a third matrix known as an <em>activation map</em>. The width, or number of columns, of the activation map is equal to the number of steps the filter takes to traverse the underlying image. Since larger strides lead to fewer steps, a big stride will produce a smaller activation map. This is important, because the size of the matrices that convolutional networks process and produce at each layer is directly proportional to how computationally expensive they are and how much time they take to train. A larger stride means less time and compute.</p>
<p>A filter superimposed on the first three rows will slide across them and then begin again with rows 4-6 of the same image. If it has a stride of three, then it will produce a matrix of dot products that is 10x10. That same filter representing a horizontal line can be applied to all three channels of the underlying image, R, G and B. And the three 10x10 activation maps can be added together, so that the aggregate activation map for a horizontal line on all three channels of the underlying image is also 10x10.</p>
<p>Now, because images have lines going in many directions, and contain many different kinds of shapes and pixel patterns, you will want to slide other filters across the underlying image in search of those patterns. You could, for example, look for 96 different patterns in the pixels. Those 96 patterns will create a stack of 96 activation maps, resulting in a new volume that is 10x10x96. In the diagram below, we’ve relabeled the input image, the kernels and the output activation maps to make sure we’re clear.</p>
<p><img src="./Convolutional Networks in Java - Deeplearning4j_ Open-source, Distributed Deep Learning for the JVM_files/karpathy-convnet-labels.png" alt="Alt text"></p>
<p>What we just described is a convolution. You can think of Convolution as a fancy kind of multiplication used in signal processing. Another way to think about the two matrices creating a dot product is as two functions. The image is the underlying function, and the filter is the function you roll over it.</p>
<iframe src="./Convolutional Networks in Java - Deeplearning4j_ Open-source, Distributed Deep Learning for the JVM_files/convgaus(1).html" width="100%" height="250px;" style="border:none;"></iframe>
<p>One of the main problems with images is that they are high-dimensional, which means they cost a lot of time and computing power to process. Convolutional networks are designed to reduce the dimensionality of images in a variety of ways. Filter stride is one way to reduce dimensionality. Another way is through downsampling.</p>
<h2 id="a-namemaxmax-poolingdownsamplinga"><a href="https://deeplearning4j.org/convolutionalnets#a-namemaxmax-poolingdownsamplinga"></a><a name="max">Max Pooling/Downsampling</a></h2>
<p>The next layer in a convolutional network has three names: max pooling, downsampling and subsampling. The activation maps are fed into a downsampling layer, and like convolutions, this method is applied one patch at a time. In this case, max pooling simply takes the largest value from one patch of an image, places it in a new matrix next to the max values from other patches, and discards the rest of the information contained in the activation maps.</p>
<p><img src="./Convolutional Networks in Java - Deeplearning4j_ Open-source, Distributed Deep Learning for the JVM_files/maxpool.png" alt="Alt text">
<em>Credit to <a href="https://cs231n.github.io/">Andrej Karpathy</a>.</em></p>
<p>Only the locations on the image that showed the strongest correlation to each feature (the maximum value) are preserved, and those maximum values combine to form a lower-dimensional space.</p>
<p>Much information about lesser values is lost in this step, which has spurred research into alternative methods. But downsampling has the advantage, precisely because information is lost, of decreasing the amount of storage and processing required.</p>
<h3 id="alternating-layers"><a href="https://deeplearning4j.org/convolutionalnets#alternating-layers">Alternating Layers</a></h3>
<p>The image below is another attempt to show the sequence of transformations involved in a typical convolutional network.</p>
<p><img src="./Convolutional Networks in Java - Deeplearning4j_ Open-source, Distributed Deep Learning for the JVM_files/convnet.png" alt="Alt text"></p>
<p>From left to right you see:</p>
<ul>
<li>The actual input image that is scanned for features. The light rectangle is the filter that passes over it.</li>
<li>Activation maps stacked atop one another, one for each filter you employ. The larger rectangle is one patch to be downsampled.</li>
<li>The activation maps condensed through downsampling.</li>
<li>A new set of activation maps created by passing filters over the first downsampled stack.</li>
<li>The second downsampling, which condenses the second set of activation maps.</li>
<li>A fully connected layer that classifies output with one label per node.</li>
</ul>
<p>As more and more information is lost, the patterns processed by the convolutional net become more abstract and grow more distant from visual patterns we recognize as humans. So forgive yourself, and us, if convolutional networks do not offer easy intuitions as they grow deeper.</p>
<h2 id="a-namecodedl4j-code-examplea"><a href="https://deeplearning4j.org/convolutionalnets#a-namecodedl4j-code-examplea"></a><a name="code">DL4J Code Example</a></h2>
<p>Here’s one example of how you might configure a ConvNet with Deeplearning4j:</p>
<script src="./Convolutional Networks in Java - Deeplearning4j_ Open-source, Distributed Deep Learning for the JVM_files/LenetMnistExample.java"></script><script type="text/javascript" src="./Convolutional Networks in Java - Deeplearning4j_ Open-source, Distributed Deep Learning for the JVM_files/prettify.js"></script><link rel="stylesheet" href="./Convolutional Networks in Java - Deeplearning4j_ Open-source, Distributed Deep Learning for the JVM_files/embed.css"><link rel="stylesheet" href="./Convolutional Networks in Java - Deeplearning4j_ Open-source, Distributed Deep Learning for the JVM_files/prettify.css"><div class="gist-it-gist">
<div class="gist-file">
    <div class="gist-data">
        
        <pre class="prettyprint"><span class="language-name"></span><a class="btn btn-sm btn-purple clipboard-copy" data-original-title="Copied!">Copy</a><span class="pln">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span><span class="typ">Create</span><span class="pln"> an iterator </span><span class="kwd">using</span><span class="pln"> the batch size </span><span class="kwd">for</span><span class="pln"> one iteration<br>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</span><span class="pun">*</span><span class="str">/<br>&nbsp; &nbsp; &nbsp; &nbsp; log.info("Load data....");<br>&nbsp; &nbsp; &nbsp; &nbsp; DataSetIterator mnistTrain = new MnistDataSetIterator(batchSize,true,12345);<br>&nbsp; &nbsp; &nbsp; &nbsp; DataSetIterator mnistTest = new MnistDataSetIterator(batchSize,false,12345);<br><br>&nbsp; &nbsp; &nbsp; &nbsp; /</span><span class="pun">*</span><span class="pln"><br>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span><span class="typ">Construct</span><span class="pln"> the neural network<br>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</span><span class="pun">*</span><span class="str">/<br>&nbsp; &nbsp; &nbsp; &nbsp; log.info("Build model....");<br>&nbsp; &nbsp; &nbsp; &nbsp; MultiLayerConfiguration.Builder builder = new NeuralNetConfiguration.Builder()<br>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; .seed(seed)<br>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; .iterations(iterations) /</span><span class="pun">/</span><span class="pln"> </span><span class="typ">Training</span><span class="pln"> iterations </span><span class="kwd">as</span><span class="pln"> above<br>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span><span class="pun">.</span><span class="pln">regularization</span><span class="pun">(</span><span class="kwd">true</span><span class="pun">).</span><span class="pln">l2</span><span class="pun">(</span><span class="lit">0.0005</span><span class="pun">)</span><span class="pln"><br>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span><span class="com">/*<br>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Uncomment the following for learning decay and bias<br>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;*/</span><span class="pln"><br>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span><span class="pun">.</span><span class="pln">learningRate</span><span class="pun">(.</span><span class="lit">01</span><span class="pun">)</span><span class="com">//.biasLearningRate(0.02)</span><span class="pln"><br>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span><span class="com">//.learningRateDecayPolicy(LearningRatePolicy.Inverse).lrPolicyDecayRate(0.001).lrPolicyPower(0.75)</span><span class="pln"><br>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span><span class="pun">.</span><span class="pln">weightInit</span><span class="pun">(</span><span class="typ">WeightInit</span><span class="pun">.</span><span class="pln">XAVIER</span><span class="pun">)</span><span class="pln"><br>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span><span class="pun">.</span><span class="pln">optimizationAlgo</span><span class="pun">(</span><span class="typ">OptimizationAlgorithm</span><span class="pun">.</span><span class="pln">STOCHASTIC_GRADIENT_DESCENT</span><span class="pun">)</span><span class="pln"><br>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span><span class="pun">.</span><span class="pln">updater</span><span class="pun">(</span><span class="typ">Updater</span><span class="pun">.</span><span class="pln">NESTEROVS</span><span class="pun">).</span><span class="pln">momentum</span><span class="pun">(</span><span class="lit">0.9</span><span class="pun">)</span><span class="pln"><br>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span><span class="pun">.</span><span class="pln">list</span><span class="pun">()</span><span class="pln"><br>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span><span class="pun">.</span><span class="pln">layer</span><span class="pun">(</span><span class="lit">0</span><span class="pun">,</span><span class="pln"> </span><span class="kwd">new</span><span class="pln"> </span><span class="typ">ConvolutionLayer</span><span class="pun">.</span><span class="typ">Builder</span><span class="pun">(</span><span class="lit">5</span><span class="pun">,</span><span class="pln"> </span><span class="lit">5</span><span class="pun">)</span><span class="pln"><br>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span><span class="com">//nIn and nOut specify depth. nIn here is the nChannels and nOut is the number of filters to be applied</span><span class="pln"><br>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span><span class="pun">.</span><span class="pln">nIn</span><span class="pun">(</span><span class="pln">nChannels</span><span class="pun">)</span><span class="pln"><br>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span><span class="pun">.</span><span class="pln">stride</span><span class="pun">(</span><span class="lit">1</span><span class="pun">,</span><span class="pln"> </span><span class="lit">1</span><span class="pun">)</span><span class="pln"><br>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span><span class="pun">.</span><span class="pln">nOut</span><span class="pun">(</span><span class="lit">20</span><span class="pun">)</span><span class="pln"><br>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span><span class="pun">.</span><span class="pln">activation</span><span class="pun">(</span><span class="str">"identity"</span><span class="pun">)</span><span class="pln"><br>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span><span class="pun">.</span><span class="pln">build</span><span class="pun">())</span><span class="pln"><br>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span><span class="pun">.</span><span class="pln">layer</span><span class="pun">(</span><span class="lit">1</span><span class="pun">,</span><span class="pln"> </span><span class="kwd">new</span><span class="pln"> </span><span class="typ">SubsamplingLayer</span><span class="pun">.</span><span class="typ">Builder</span><span class="pun">(</span><span class="typ">SubsamplingLayer</span><span class="pun">.</span><span class="typ">PoolingType</span><span class="pun">.</span><span class="pln">MAX</span><span class="pun">)</span><span class="pln"><br>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span><span class="pun">.</span><span class="pln">kernelSize</span><span class="pun">(</span><span class="lit">2</span><span class="pun">,</span><span class="lit">2</span><span class="pun">)</span><span class="pln"><br>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span><span class="pun">.</span><span class="pln">stride</span><span class="pun">(</span><span class="lit">2</span><span class="pun">,</span><span class="lit">2</span><span class="pun">)</span><span class="pln"><br>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span><span class="pun">.</span><span class="pln">build</span><span class="pun">())</span><span class="pln"><br>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span><span class="pun">.</span><span class="pln">layer</span><span class="pun">(</span><span class="lit">2</span><span class="pun">,</span><span class="pln"> </span><span class="kwd">new</span><span class="pln"> </span><span class="typ">ConvolutionLayer</span><span class="pun">.</span><span class="typ">Builder</span><span class="pun">(</span><span class="lit">5</span><span class="pun">,</span><span class="pln"> </span><span class="lit">5</span><span class="pun">)</span><span class="pln"><br>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span><span class="com">//Note that nIn need not be specified in later layers</span><span class="pln"><br>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span><span class="pun">.</span><span class="pln">stride</span><span class="pun">(</span><span class="lit">1</span><span class="pun">,</span><span class="pln"> </span><span class="lit">1</span><span class="pun">)</span><span class="pln"><br>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span><span class="pun">.</span><span class="pln">nOut</span><span class="pun">(</span><span class="lit">50</span><span class="pun">)</span><span class="pln"><br>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span><span class="pun">.</span><span class="pln">activation</span><span class="pun">(</span><span class="str">"identity"</span><span class="pun">)</span><span class="pln"><br>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span><span class="pun">.</span><span class="pln">build</span><span class="pun">())</span><span class="pln"><br>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span><span class="pun">.</span><span class="pln">layer</span><span class="pun">(</span><span class="lit">3</span><span class="pun">,</span><span class="pln"> </span><span class="kwd">new</span><span class="pln"> </span><span class="typ">SubsamplingLayer</span><span class="pun">.</span><span class="typ">Builder</span><span class="pun">(</span><span class="typ">SubsamplingLayer</span><span class="pun">.</span><span class="typ">PoolingType</span><span class="pun">.</span><span class="pln">MAX</span><span class="pun">)</span><span class="pln"><br>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span><span class="pun">.</span><span class="pln">kernelSize</span><span class="pun">(</span><span class="lit">2</span><span class="pun">,</span><span class="lit">2</span><span class="pun">)</span><span class="pln"><br>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span><span class="pun">.</span><span class="pln">stride</span><span class="pun">(</span><span class="lit">2</span><span class="pun">,</span><span class="lit">2</span><span class="pun">)</span><span class="pln"><br>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span><span class="pun">.</span><span class="pln">build</span><span class="pun">())</span></pre>
        
    </div>
    
    <div class="gist-meta">
        
        <span><a href="https://github.com/deeplearning4j/dl4j-examples/blob/master/dl4j-examples/src/main/java/org/deeplearning4j/examples/convolution/LenetMnistExample.java">This Gist</a> brought to you by <a href="https://gist-it.appspot.com/">gist-it</a>.</span>
        
        <span style="float: right; color: #369;"><a href="https://github.com/deeplearning4j/dl4j-examples/raw/master/dl4j-examples/src/main/java/org/deeplearning4j/examples/convolution/LenetMnistExample.java">view raw</a></span>
        <span style="float: right; margin-right: 8px;">
            <a style="color: rgb(102, 102, 102);" href="https://github.com/deeplearning4j/dl4j-examples/blob/master/dl4j-examples/src/main/java/org/deeplearning4j/examples/convolution/LenetMnistExample.java">dl4j-examples/src/main/java/org/deeplearning4j/examples/convolution/LenetMnistExample.java</a></span>
            <!-- Generated by: https://gist-it.appspot.com -->
    </div>
    
</div>
</div><script type="text/javascript">prettyPrint();</script>
<h3 id="a-namebeginnerother-deeplearning4j-tutorialsa"><a href="https://deeplearning4j.org/convolutionalnets#a-namebeginnerother-deeplearning4j-tutorialsa"></a><a name="beginner">Other Deeplearning4j Tutorials</a></h3>
<ul>
<li><a href="https://deeplearning4j.org/neuralnet-overview">Introduction to Neural Networks</a></li>
<li><a href="https://deeplearning4j.org/lstm">LSTMs and Recurrent Networks</a></li>
<li><a href="https://deeplearning4j.org/word2vec">Word2vec</a></li>
<li><a href="https://deeplearning4j.org/restrictedboltzmannmachine">Restricted Boltzmann Machines</a></li>
<li><a href="https://deeplearning4j.org/eigenvector">Eigenvectors, Covariance, PCA and Entropy</a></li>
<li><a href="https://deeplearning4j.org/linear-regression">Neural Networks and Regression</a></li>
</ul>
<h2 id="a-nameresourceother-resourcesa"><a href="https://deeplearning4j.org/convolutionalnets#a-nameresourceother-resourcesa"></a><a name="resource">Other Resources</a></h2>
<ul>
<li><a href="http://yann.lecun.com/exdb/publis/pdf/lecun-iscas-10.pdf">Yann LeCun</a>, a professor at New York University and director of research at Facebook, has done much to advance and promote the use of convolutional nets, which are used heavily in machine vision tasks.</li>
<li><a href="https://cs231n.github.io/">Andrej Karpathy’s Stanford course</a> on Convolutional Nets is fantastic. We highly recommend it as an introduction to the major ideas. (<em>Exercises in Python.</em>)</li>
<li>To see DL4J convolutional networks in action, please run our <a href="https://github.com/deeplearning4j/dl4j-examples/tree/master/dl4j-examples/src/main/java/org/deeplearning4j/examples/convolution/">examples</a> after following the instructions on the <a href="https://deeplearning4j.org/quickstart">Quickstart page</a>.</li>
</ul>
</article>
 
</div>
</main>
 
<footer class="site-footer">
<div class="container">
<a id="scroll-up" href="https://deeplearning4j.org/convolutionalnets#"><i class="fa fa-angle-up"></i></a>
<div class="row">
<div class="col-md-6 col-sm-6">
<p>Copyright © 2016. <a href="https://www.skymind.io/?__hstc=3042607.a778a5c844b06db899d0b88c76db3380.1481413138352.1481413138352.1481413138352.1&amp;__hssc=3042607.2.1481413138353&amp;__hsfp=1444234784">Skymind</a>. DL4J is distributed under an Apache 2.0 License.</p>
</div>
<div class="col-md-6 col-sm-6">
<ul class="footer-menu">
<li><a href="https://github.com/deeplearning4j/">Github</a></li>
<li><a href="https://twitter.com/deeplearning4j">Tweets</a></li>
<li><a href="https://www.facebook.com/deeplearning4j/">Facebook</a></li>
<li><a href="https://deeplearning4j.org/cn/index">中文</a></li>
<li><a href="https://deeplearning4j.org/ja-index">日本語</a></li>
<li><a href="https://deeplearning4j.org/kr-index">한글</a></li>
<li><a href="http://nd4j.org/">ND4J</a></li>
</ul>
</div>
</div>
</div>
</footer>
 
 
<script src="./Convolutional Networks in Java - Deeplearning4j_ Open-source, Distributed Deep Learning for the JVM_files/theDocs.all.min.js"></script>
<script src="./Convolutional Networks in Java - Deeplearning4j_ Open-source, Distributed Deep Learning for the JVM_files/theDocs.js"></script>
 
 
<script type="text/javascript">
  (function() {
    var li = document.createElement('script'); li.type = 'text/javascript'; li.async = true;
    li.src = ('https:' == document.location.protocol ? 'https:' : 'http:') + '//platform.stumbleupon.com/1/widgets.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(li, s);
  })();
</script>
<script>
  ((window.gitter = {}).chat = {}).options = {
    room: 'deeplearning4j/deeplearning4j'
  };
</script>
<script src="./Convolutional Networks in Java - Deeplearning4j_ Open-source, Distributed Deep Learning for the JVM_files/sidecar.v1.js" async="" defer=""></script>
 


<aside class="gitter-chat-embed is-collapsed"><div class="gitter-chat-embed-action-bar"><a class="gitter-chat-embed-action-bar-item gitter-chat-embed-action-bar-item-pop-out" aria-label="Open Chat in Gitter.im" href="https://gitter.im/deeplearning4j/deeplearning4j" target="_blank"></a><button class="gitter-chat-embed-action-bar-item gitter-chat-embed-action-bar-item-collapse-chat" aria-label="Collapse Gitter Chat"></button></div><div class="gitter-chat-embed-loading-wrapper">
        <div class="gitter-chat-embed-loading-indicator gitter-icon"></div>
      </div></aside><a href="https://gitter.im/deeplearning4j/deeplearning4j" class="gitter-open-chat-button">Open Chat</a><div id="wrtio-ui-wrapper" stlye="height:100%; width:100%;"><iframe id="writio-side-iframe" src="./Convolutional Networks in Java - Deeplearning4j_ Open-source, Distributed Deep Learning for the JVM_files/index(1).html" scrolling="no" frameborder="0" style="right: -360px !important; width: 340px !important;"></iframe><iframe id="writio-notification-iframe" src="./Convolutional Networks in Java - Deeplearning4j_ Open-source, Distributed Deep Learning for the JVM_files/index(2).html" scrolling="no" frameborder="0" style="opacity: 0 !important; visibility: hidden !important;"></iframe></div><div id="writio-popover-share-wrapper" style="top: 5151px !important; left: 347px !important; display: none;"><div id="writio-popover-share-inner">


    <div class="writio-popover-share-list">
        <div id="writio-popover-share-h1"><i id="writio-circle-1" class="writio-circle writio-circle-dim writio-red"></i></div>
        <div id="writio-popover-share-h2"><i id="writio-circle-2" class="writio-circle writio-circle-dim writio-orange"></i></div>
        <div id="writio-popover-share-h3"><i id="writio-circle-3" class="writio-circle writio-circle-dim writio-yellow"></i></div>
        <div id="writio-popover-share-h4"><i id="writio-circle-4" class="writio-circle writio-circle-dim writio-green"></i></div>
        <div id="writio-popover-share-h5"><i id="writio-circle-5" class="writio-circle writio-circle-dim writio-blue" style="margin-right: 0px !important; width: 23px !important;"></i>
        </div>
        <div id="writio-popover-pointer" style="top: -14px !important;"></div>
    </div>

    <div id="writio-popover-folder-dropdown">
        <div id="writio-popover-folder-block">
            <div class="writio-popover-folder-text-wrapper">in</div>
            <div id="writio-popover-active-folder-wrapper">
                <div id="writio-popover-active-folder-name">My Collection</div>
                <svg id="writio-popover-active-folder-dropdown-icon" width="7px" height="5px" viewBox="405 533 7 5" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
                    <defs></defs>
                    <polygon id="writio-popover-dropdown-rectangle" points="405 533 412 533 408.5 538"></polygon>
                </svg>
            </div>

        </div>
        <ul id="writio-popover-folder-list" class="writio-popover-folder-list-deactive"><li id="writio-popover-dropdown-list-item-new-collection" class="writio-popover-dropdown-list-item">+ Create new collection</li></ul>
    </div>

    <svg id="writio-popover-settings-icon" width="13px" height="13px" viewBox="0 0 82 82" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
        <defs></defs>
        <path d="M79.9,49.8 C77.5,47.5 76.2,44.3 76.2,41 C76.2,37.7 77.5,34.6 79.9,32.2 C80.3,31.8 80.7,31.5 81.2,31.1 C81.9,30.6 82.1,29.7 81.9,28.9 C81.1,26 79.9,23.2 78.5,20.6 C78.1,19.9 77.3,19.5 76.5,19.6 C75.8,19.7 75.3,19.7 74.8,19.7 C67.9,19.7 62.3,14.1 62.3,7.3 C62.3,6.8 62.3,6.2 62.4,5.6 C62.5,4.8 62.1,4 61.4,3.6 C58.8,2.2 56,1 53.1,0.2 C52.3,-1.97619698e-14 51.4,0.3 50.9,0.9 C50.5,1.4 50.1,1.9 49.8,2.2 C47.4,4.5 44.3,5.8 41,5.8 C37.7,5.8 34.5,4.5 32.2,2.2 C31.8,1.8 31.5,1.4 31.1,0.9 C30.6,0.2 29.7,-2.15383267e-14 28.9,0.2 C26,1.1 23.2,2.2 20.6,3.6 C19.9,4 19.5,4.8 19.6,5.6 C19.7,6.3 19.7,6.8 19.7,7.3 C19.7,14.2 14.1,19.7 7.2,19.7 C6.7,19.7 6.1,19.7 5.5,19.6 C4.7,19.5 3.9,19.9 3.5,20.6 C2.1,23.2 0.9,26 0.1,28.9 C-0.1,29.7 0.1,30.6 0.8,31.1 C1.4,31.5 1.8,31.9 2.1,32.2 C7,37 7,44.9 2.1,49.8 C1.7,50.2 1.3,50.5 0.8,50.9 C0.1,51.4 -0.1,52.3 0.1,53.1 C1,56 2.1,58.8 3.5,61.4 C3.9,62.1 4.7,62.5 5.5,62.4 C6.2,62.3 6.7,62.3 7.2,62.3 C14.1,62.3 19.7,67.9 19.7,74.7 C19.7,75.2 19.7,75.8 19.6,76.4 C19.5,77.2 19.9,78 20.6,78.4 C23.2,79.8 26,81 28.9,81.8 C29.7,82 30.6,81.8 31.1,81.1 C31.5,80.6 31.9,80.1 32.2,79.8 C34.6,77.5 37.7,76.2 41,76.2 C44.3,76.2 47.5,77.5 49.8,79.8 C50.2,80.2 50.5,80.6 50.9,81.1 C51.3,81.6 51.9,81.9 52.5,81.9 C52.7,81.9 52.9,81.9 53.1,81.8 C56,80.9 58.8,79.8 61.4,78.4 C62.1,78 62.5,77.2 62.4,76.4 C62.3,75.7 62.3,75.2 62.3,74.7 C62.3,67.8 67.9,62.3 74.8,62.3 C75.3,62.3 75.9,62.3 76.5,62.4 C77.3,62.5 78.1,62.1 78.5,61.4 C79.9,58.8 81.1,56 81.9,53.1 C82.1,52.3 81.9,51.4 81.2,50.9 C80.7,50.5 80.2,50.2 79.9,49.8 L79.9,49.8 Z M75.6,58.3 L74.7,58.3 C65.6,58.3 58.2,65.7 58.2,74.7 L58.2,75.6 C56.6,76.4 54.9,77.1 53.1,77.7 C52.9,77.5 52.7,77.3 52.5,77.1 C49.4,74 45.3,72.3 40.9,72.3 C36.5,72.3 32.4,74 29.3,77.1 C29.1,77.3 28.9,77.5 28.7,77.7 C27,77.1 25.3,76.4 23.6,75.6 L23.6,74.7 C23.6,65.6 16.2,58.3 7.1,58.3 L6.2,58.3 C5.4,56.7 4.7,55 4.1,53.2 C4.3,53 4.5,52.8 4.7,52.6 C11.1,46.2 11.1,35.8 4.7,29.3 C4.5,29.1 4.3,28.9 4.1,28.7 C4.7,27 5.4,25.3 6.2,23.6 L7.1,23.6 C16.2,23.6 23.6,16.2 23.6,7.2 L23.6,6.3 C25.2,5.5 26.9,4.8 28.7,4.2 C28.9,4.4 29.1,4.6 29.3,4.8 C32.4,7.9 36.5,9.6 40.9,9.6 C45.3,9.6 49.4,7.9 52.5,4.8 C52.7,4.6 52.9,4.4 53.1,4.2 C54.8,4.8 56.5,5.5 58.2,6.3 L58.2,7.2 C58.2,16.3 65.6,23.6 74.7,23.6 L75.6,23.6 C76.4,25.2 77.1,26.9 77.7,28.7 C77.5,28.9 77.3,29.1 77.1,29.3 C74,32.4 72.3,36.5 72.3,40.9 C72.3,45.3 74,49.4 77.1,52.5 C77.3,52.7 77.5,52.9 77.7,53.1 C77.1,55 76.4,56.7 75.6,58.3 L75.6,58.3 Z M41,17.2 C27.9,17.2 17.2,27.9 17.2,41 C17.2,54.1 27.9,64.8 41,64.8 C54.1,64.8 64.8,54.1 64.8,41 C64.8,27.9 54.1,17.2 41,17.2 L41,17.2 Z M41,60.8 C30.1,60.8 21.2,51.9 21.2,41 C21.2,30.1 30.1,21.2 41,21.2 C51.9,21.2 60.8,30.1 60.8,41 C60.8,51.9 51.9,60.8 41,60.8 L41,60.8 Z" id="Shape" stroke="none" fill-rule="evenodd"></path>
    </svg>
    <!--Drop down folder list-->

</div></div><div id="twc-app-root"><div class="twc-root" data-reactid=".0"><div class="twc-screenshotter" data-reactid=".0.1"><div style="display:none;" data-reactid=".0.1.0"></div><div class="twc-quote-controller is-controller-hidden" data-reactid=".0.1.1"><div class="twc-quote-button" data-reactid=".0.1.1.0"><i class="twcicn twcicn-twitter-shot" data-reactid=".0.1.1.0.0"></i></div></div></div></div></div></body></html>