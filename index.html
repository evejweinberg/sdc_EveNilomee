<!DOCTYPE html>
<html lang="en">

<head>

  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="description" content="">
  <meta name="author" content="">

  <title>Software on Wheels</title>

  <!-- Bootstrap Core CSS -->
  <link href="vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">

  <!-- Custom Fonts -->
  <link href="https://fonts.googleapis.com/css?family=Lato" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css?family=Catamaran:100,200,300,400,500,600,700,800,900" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css?family=Muli" rel="stylesheet">

  <!-- Plugin CSS -->
  <link rel="stylesheet" href="vendor/font-awesome/css/font-awesome.min.css">
  <link rel="stylesheet" href="vendor/simple-line-icons/css/simple-line-icons.css">
  <link rel="stylesheet" href="vendor/device-mockups/device-mockups.min.css">

  <!-- Theme CSS -->
  <link href="css/new-age.css" rel="stylesheet">



</head>

<body id="page-top">

  <nav id="mainNav" class="navbar navbar-default navbar-fixed-top">
    <div class="container">
      <!-- Brand and toggle get grouped for better mobile display -->
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
          <span class="sr-only">Toggle navigation</span> Menu <i class="fa fa-bars"></i>
        </button>
        <a class="navbar-brand page-scroll" href="#page-top">How do Self Driving Cars Really work?
        </a>
      </div>

      <!-- Collect the nav links, forms, and other content for toggling -->
      <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
        <ul class="nav navbar-nav navbar-right">
          <li>
            <a class="page-scroll" href="#training">Training</a>
          </li>
          <li>
            <a class="page-scroll" href="#radar">Radar</a>
          </li>

          <li>
            <a class="page-scroll" href="#lidar">Lidar</a>
          </li>

          <li>
            <a class="page-scroll" href="#ultrasonic">UltraSonic</a>
          </li>

          <li>
            <a class="page-scroll" href="#cv">Computer Vision</a>
          </li>
          <li>
            <a class="page-scroll" href="#fusion">Fusion</a>
          </li>
          <!-- <li>
          <a class="page-scroll" href="#contact">GPS</a>
        </li> -->
        <li>
          <a class="page-scroll" href="#about">About</a>
        </li>
        <li>
          <a class="page-scroll" href="#resources">Resources</a>
        </li>
      </ul>
    </div>
    <!-- /.navbar-collapse -->
  </div>
  <!-- /.container-fluid -->
</nav>

<header>
  <div class="container">
    <div class="row">
      <div class="col-sm-7">
        <div class="header-content">
          <div class="header-content-inner">
            <h1>"A car is just software on wheels" <br><small>-NVIDIA Creator Jen-Hsun Huang
            </small></h1>
          </div>
        </div>
      </div>
      <div class="col-sm-5">

        <div class="device-container">
          <a href="http://vicinitysolutions.co.nz/geoblog.php" target="_blank">
            <img src="img/cd.gif" class="img-responsive" alt="" >
          </a>
          <a href="http://slides.com/wilthomason/computer-vision" target="_blank">
            <img src="img/roadcv.gif" class="img-responsive" alt="" >
          </a>
          <!--  <div class="device-mockup iphone6_plus portrait white">
          <div class="device">
          <div class="screen">
          <img src="img/lidar/1.jpg" class="img-responsive" alt="">
        </div>
        <div class="button">
      </div>
    </div>
  </div>-->
</div>
</div>
</div>
</div>
</header>

<hr width="90%"></hr>


<section id="training" class="features">
  <div class="container">
    <div class="row">
      <div class="col-lg-10 col-lg-offset-1 text-center">
        <h2>Training</h2>


        <p> For any car to be smart enough to drive safely on the road, they must be trained for thousands of hours on millions of frames of video.

          All companies researching autonomous vehicles use Machine Learning to create the most comprehensive 360 3D view from the car’s perspective.


        </p>
        <a href="https://www.youtube.com/watch?v=KkpxA5rXjmA" target="_blank">
          <img src="img/lidar/cv.gif" alt=""></a>
          <br>
          <br>
          <p>The animation above is from NVIDIA's training program. They created a system called DriveNet which was trained on a group of <strong> 1.2 million images</strong> called 'ImageNet'. They actually warped the images and falsely color corrected them to make the trianing set 10 times as large.
            They fed these images to a convolutional neural network to create 1,000 different classes (ex: person, two people, street sign, dog, fire hydrant, cloud, etc). Using their accelerated GPUs, they
            were able to do this classification in only 1 month. Any other hardware would have taken a couple of years to train this neural network.
            Now, this same neural network can go beyond classification and actually detect these objects. NVIDIA calls this system CityScape and they will be sharing it. The video above shows a work-in-progress stage where it detected bounding boxes, then it learned to identify individual pixels and connect them with objects, color coding the exact pixels of each object.
          </p>


        </div>
      </div>
      <div class="col-sm-6">

        <!-- <p>Radar is Radio waves.
        They travel far, are invisible to humans and are easy to detect even when they are faint. High-end cars already bristle with radar, which can track nearby objects. For instance, Mercedes’ Distronic Plus, an accident-prevention system, includes units on the rear bumper that trigger an alert when they detect something in the car’s blind spot.
      </p> -->
    </div>

  </div>
</div>
</div>
<a href="#radar" class="btn btn-circle page-scroll"><i class="fa fa-angle-double-down animated"></i></a>


</section>





<section id="radar" class="features">
  <div class="container">
    <div class="row">
      <div class="col-lg-10 col-lg-offset-1 text-center">
        <h2>Radar</h2>
        <hr class="small">
        <div class="row">
          <div class="col-sm-3" id="tight-grid">
            <div class="portfolio-item">
              <a href="https://www.youtube.com/watch?v=rmY1irCK3iw">
                <img class="img-portfolio img-responsive" src="img/radar/radar.png">
              </a>
            </div>
          </div>
          <div class="col-sm-3" id="tight-grid">
            <div class="portfolio-item">
              <a href="#">
                <img class="img-portfolio img-responsive" src="img/radar/grad.png">
              </a>
            </div>
          </div>
          <div class="col-sm-3" id="tight-grid">
            <div class="portfolio-item">
              <a href="#">
                <img class="img-portfolio img-responsive" src="img/radar/spectrum.jpg">
              </a>
            </div>
          </div>
          <div class="col-sm-3" id="tight-grid">
            <div class="portfolio-item">
              <a href="#">
                <img class="img-portfolio img-responsive" src="img/radar/large.png">
              </a>
            </div>
          </div>
        </div>

      </div>

    </div>

  </div>
  <hr class="spacer"></hr>
  <div class="container">
    <div class="row">
      <div class="col-lg-10 col-lg-offset-1 text-left">
        <div class="col-sm-6">

          <div class="device-container">
            <img src="img/drawing_radar1.png" class="img-responsive" alt="" >


            <!-- <a href="http://slides.com/wilthomason/computer-vision" target="_blank">
              <img src="img/roadcv.gif" class="img-responsive" alt="" >
            </a> -->

          </div>
        </div>
        <div class="col-sm-6">

          <p>Radar (RAdio Detection And Ranging) is radio waves.
            They travel far, are invisible to humans and are easy to detect even when they are faint. High-end cars already have radar to track nearby objects and control the speed of the car for you. Mercedes’ Distronic Plus accident-prevention system includes units on the rear bumper that trigger an alert when they detect something in the car’s blind spot. Google's self driving car has 4 radars, 2 on the back bumper, 2 on the front, and their main purpose it to maintain at least a 2-4 second distance between the car and all other objects.
          </p>
        </div>

      </div>
    </div>
  </div>
  <a href="#lidar" class="btn btn-circle page-scroll"><i class="fa fa-angle-double-down animated"></i></a>


</section>









<section id="lidar" class="features">
  <div class="container">
    <div class="row">
      <div class="col-lg-10 col-lg-offset-1 text-center">
        <h2>LiDAR</h2>
        <hr class="small">
        <div class="row">
          <div class="col-sm-3" id="tight-grid">
            <div class="portfolio-item">
              <a href="#">
                <img class="img-portfolio img-responsive" src="img/lidar/1.jpg">
              </a>
            </div>
          </div>
          <div class="col-sm-3" id="tight-grid">
            <div class="portfolio-item">
              <a href="#">
                <img class="img-portfolio img-responsive" src="img/lidar/0.gif">
              </a>
            </div>
          </div>
          <div class="col-sm-3" id="tight-grid">
            <div class="portfolio-item">
              <a href="#">
                <img class="img-portfolio img-responsive" src="img/lidar/2.gif">
              </a>
            </div>
          </div>
          <div class="col-sm-3" id="tight-grid">
            <div class="portfolio-item">
              <a href="#">
                <img class="img-portfolio img-responsive" src="img/lidar/3.gif">
              </a>
            </div>
          </div>
        </div>

      </div>

    </div>

  </div>
  <hr class="spacer"></hr>
  <div class="container">
    <div class="row">
      <div class="col-lg-10 col-lg-offset-1 text-left">
        <div class="col-sm-6">

          <div class="device-container">
            <a href="" target="_blank">
              <img src="img/drawing_lidar1.jpg" class="img-responsive" alt="" >
            </a>
            <!-- <a href="http://slides.com/wilthomason/computer-vision" target="_blank">
              <img src="img/roadcv.gif" class="img-responsive" alt="" >
            </a> -->

          </div>
        </div>
        <div class="col-sm-6">

          <p>LiDAR (Light Detection and Ranging) works like radar, but with pulses of light rather than radio waves.
            It calculates how far an object is from the moving vehicle based on the time it takes for the laser beams to hit the object and come back.

            Cars use lidar for obstacle detection and avoidance to navigate safely through environments. The LiDAR sensor sits at the top center of the car, revolving around 900 rotations/minute. Point cloud outputs from the lidar sensor provide the necessary data for software to determine where potential obstacles exist in the environment. Google employs Velodyne’s rooftop Light Detection and Ranging system, which uses 64 lasers, spinning at upwards of 900 rpm, to generate a point cloud that gives the car a 360-degree view.
          </p>
        </div>

      </div>
    </div>
  </div>

  <a href="#ultrasonic" class="btn btn-circle page-scroll"><i class="fa fa-angle-double-down animated"></i></a>


</section>






<section id="ultrasonic" class="features">
  <div class="container">
    <div class="row">
      <div class="col-lg-10 col-lg-offset-1 text-center">
        <h2>Ultrasonic</h2>
        <hr class="small">
        <div class="row">
          <div class="col-sm-3" id="tight-grid">
            <div class="portfolio-item">
              <a href="#">
                <!-- <img class="img-portfolio img-responsive" src="img/bg-cta.jpg"> -->
              </a>
            </div>
          </div>
          <div class="col-sm-3" id="tight-grid">
            <div class="portfolio-item">
              <a href="#">
                <!-- <img class="img-portfolio img-responsive" src="img/bg-cta.jpg"> -->
              </a>
            </div>
          </div>
          <div class="col-sm-3" id="tight-grid">
            <div class="portfolio-item">
              <a href="#">
                <img class="img-portfolio img-responsive" src="img/ultra/2.jpg">
              </a>
            </div>
          </div>
          <div class="col-sm-3" id="tight-grid">
            <div class="portfolio-item">
              <a href="#">
                <img class="img-portfolio img-responsive" src="img/ultra/1.jpg">
              </a>
            </div>
          </div>
        </div>

      </div>

    </div>

  </div>
  <hr class="spacer"></hr>
  <div class="container">
    <div class="row">
      <div class="col-lg-10 col-lg-offset-1 text-left">
        <div class="col-sm-6">

          <div class="device-container">
              <img src="img/drawing_us1.jpg" class="img-responsive" alt="" >

            <!-- <a href="http://slides.com/wilthomason/computer-vision" target="_blank">
              <img src="img/roadcv.gif" class="img-responsive" alt="" >
            </a> -->

          </div>
        </div>
        <div class="col-sm-6">

          <p>An ultrasonic wave is a sound wave with a very high frequency (above 20,000 Hz) inaudible to humans. Ultrasonic detectors provide more accurate mapping of the surroundings at very short range. If you have a car that helps you park and backup, it's already using ultrasonic. It handles a rangle of about 1.2 to 4.5 meters. In self-driving cars, the ultrasonic sensors are in the wheels, as shown to the left.
          </p>
        </div>

      </div>
    </div>
    <a href="#cv" class="btn btn-circle page-scroll"><i class="fa fa-angle-double-down animated"></i></a>
  </div>


</section>




<section id="cv" class="features">
  <div class="container">
    <div class="row">
      <div class="col-lg-10 col-lg-offset-1 text-center">
        <h2>Computer Vision</h2>
        <h3>How do we get from camera input to classification?</h3>
        <hr class="small">
        <a href="#">
          <img class="img-portfolio img-responsive" src="img/sara.png">
        </a>
        <br>
        <br>
        <br>
        <p>Computer Vision requires using a convolutional neural network. The images below all link to great articles explaining how this works.
        </p>
        <br><br>
        <div class="row">
          <div class="col-sm-3" id="tight-grid">
            <div class="portfolio-item">
              <iframe class="img-portfolio img-responsive" width="284" height="160" src="https://www.youtube.com/embed/FmpDIaiMIeA" frameborder="0" allowfullscreen></iframe>
              <!-- <a href="https://www.youtube.com/watch?v=FmpDIaiMIeA">
              <img class="img-portfolio img-responsive" src="img/cv/cv1.png">
            </a> -->
          </div>
        </div>
        <div class="col-sm-3" id="tight-grid">
          <div class="portfolio-item">
            <a href="https://medium.com/technologymadeeasy/the-best-explanation-of-convolutional-neural-networks-on-the-internet-fbb8b1ad5df8#.l7ge7e5l0" target="_blank">
              <img class="img-portfolio img-responsive" src="img/cv/cvB.png">
            </a>
          </div>
        </div>
        <div class="col-sm-3" id="tight-grid">
          <div class="portfolio-item">
            <a href="https://indico.io/blog/exploring-computer-vision-convolutional-neural-nets/" target="_blank">
              <img class="img-portfolio img-responsive" src="img/cv/cv2.png">
            </a>
          </div>

        </div>
        <div class="col-sm-3" id="tight-grid">
          <div class="portfolio-item">
            <a href="#">
              <!-- <img class="img-portfolio img-responsive" src="img/ultra/1.jpg"> -->
            </a>
          </div>
        </div>


      </div>

    </div>

  </div>

</div>
<hr class="spacer"></hr>
<div class="container">
  <div class="row">
    <!-- <div class="col-lg-10 col-lg-offset-1 text-left"> -->
      <div class="col-sm-6">

        <div class="device-container bordered-img">
          <a href="" target="_blank">
            <img src="img/cv/cv_layers.png" class="img-responsive" alt="" >
          </a>
          <a href="" target="_blank">
            <img src="img/cv/cv_layers2.png" class="img-responsive" alt="" >
          </a>



        </div>
      </div>
      <div class="col-sm-6">

        <div class="device-container">
          <p>STEP1: Convolution Neural Networks are a layered process. The two images to the left both attempt to show how the system gets from the input image to the output classification. Let's break down this diagram and, as shown, start with a square image that is 32px wide and 32px tall.</p>


        </div>
      </div>





  </div>

    <hr class="spacer"></hr>

  <div class="row">
      <div class="col-sm-6">
        <div class="device-container">
          <a href="" target="_blank">
            <img src="img/cv/cv_feature.gif" class="img-responsive bordered-img" alt="">
          </a>
        </div>
      </div>
      <div class="col-sm-6">

        <div class="device-container">
          <p>STEP 2: Rather than focus on one pixel at a time, a convolutional net looks at the image by analyzing patches at a time. Most examples show a 5px x 5px feature analysis. Let's say that our first feature layer is looking for edges. It will scan the 32x32 image 25 pixels at a time (5px x 5px), recording wether or not that patch has an edge. Iterating through the image, building a new array of information, if the feature believes that the input image has an edge, then it pushes a 1 to the next layer, otherwise a -1.
            This creates a new layer that is a smaller array of information than the previous one.
            In the case of self driving cars, some neural networks have been trained with 96 different feature layers (edge detection being 1 of those 96).
          </p>
          <br>
          <p><i>Note: the image is showing a 7px x 7px image being reduced to a 5px x 5px array of information</i></p>
        </div>
      </div>
  </div>


  <hr class="spacer"></hr>

<div class="row">
    <div class="col-sm-6">
      <div class="device-container">
        <a href="" target="_blank">
          <img src="img/cv/pooling.jpg" class="img-responsive bordered-img" alt="">
        </a>
      </div>
    </div>
    <div class="col-sm-6">

      <div class="device-container">
        <p>STEP 3: Now we have an array for each feature that is basically a map indicating where in the image that feature probably appears (on a scale of -1 to 1). If the feature we're looking for is a diagnal line, the new array would have a 1 everywhere there is definitely a dignal line going through those pixels.
        </p>

        <br>
        <p>Ref: <a href="https://www.youtube.com/watch?v=FmpDIaiMIeA"> 'How Convolutional Neural Networks work' </a> YouTube Video</p>
      </div>
    </div>
</div>




<hr class="spacer"></hr>

<div class="row">
  <div class="col-sm-6">
    <div class="device-container">
      <a href="" target="_blank">
        <img src="img/cv/poolingB.jpg" class="img-responsive bordered-img" alt="">
      </a>
    </div>
  </div>
  <div class="col-sm-6">

    <div class="device-container">
      <p>STEP 4: POOLING. For every convolved (filtered) layer, we pool it. This simpy means to take the largest value in a pre-defined pixel square, and push that into a new pooled layer that will have significantly less numbers in it.
      </p>

      <br>
    </div>
  </div>
</div>



<hr class="spacer"></hr>

<div class="row">
  <div class="col-sm-6">
    <div class="device-container">
      <a href="" target="_blank">
        <img src="img/cv/FinalPool.jpg" class="img-responsive bordered-img" alt="">
      </a>
    </div>
  </div>
  <div class="col-sm-6">

    <div class="device-container">
      <p>STEP 5: Final Vote. After enough iterations of convolving and pooling, each pooled number now predicts what the image is.

      <br>
    </div>
  </div>
</div>






</div>







<a href="#fusion" class="btn btn-circle page-scroll"><i class="fa fa-angle-double-down animated"></i></a>


</section>


<section id="fusion" class="features">
  <div class="container">
    <div class="row">
      <div class="col-lg-10 col-lg-offset-1 text-center">
        <h2>Sensor Fusion</h2>
        <hr class="spacer"></hr>

        <a href="#">
          <img class="img-portfolio img-responsive" src="img/fusion/all2.jpg">
        </a>
        <div class="row">
<br>

        </div>

      </div>

    </div>

  </div>

  <div class="container">
    <div class="row">
      <div class="col-lg-10 col-lg-offset-1 text-left">
        <div class="col-sm-6">

          <!-- <div class="device-container">
          <a href="http://vicinitysolutions.co.nz/geoblog.php" target="_blank">
          <img src="img/cd.gif" class="img-responsive" alt="" >
        </a>
        <a href="http://slides.com/wilthomason/computer-vision" target="_blank">
        <img src="img/roadcv.gif" class="img-responsive" alt="" >
      </a>

    </div> -->
  </div>
  <div class="col-sm-12">
    <p>Sensor fusion is the process of combining all sensory data derived from the sensors fitted on the car. The data is analysed in stages to identify the car’s location and its surroundings. For a car to be able to drive itself, it requires sensors fitted on the car, a powerful computer and a GPU. The GPU is where the real time computing takes place, thus the PX2 GPU manufactured by NVIDIA is the top choice for car companies building Self Driving cars.</p>


<br><br>
<p>
<strong>How the car analyses data and makes decisions:</strong>
<br>
<br>
The car is receiving inputs in the form of weather data, image data and sensory data from the sensors like the Ultrasonic Sensor, Radar, Lidar and GPS. The sensory data from each sensor is analysed individually to detect an obstacle and create a depth map.
<br>

The 2 field view cameras fitted at the front and at the back of the car are. The images captured are taken through a network called DriveNet, that has been trained by NVIDIA on ImageNet to recognize a range of automotives like cars, busses etc. (ImageNet is a database of over 15 million hand labelled images that learning algorithms are trained on). This enables the car to recognize the obstacles by their name.

<br>
The Lidar sensor create depth map that is a dynamic 3D model of the environment from point cloud data.
<br>
<br>
<strong>Data Fusion:</strong>
<br>
<br>
Based on the inputs from the depth maps, a 2D occupancy grid is created that encodes which cells contain depth measurements. From this grid, the sensory fusion algorithm extracts obstacles from the occupied cells and refines their positions, to determine the uncertainty of each detection.

<br>
The car assumes that it is moving on a plane, and any object that is not on the plane is identified as a potential obstacle. Each grid cell is checked to see if it is occupied and is initialized with weight zero and updated whenever new obstacle detections are available by adding the respective weight to the grid cells The update is constantly performed in a separate compute thread concurrent to depth map generation and obstacle detection and to update the occupancy map.

<br>

The occupancy map is color coded using the data received from the sensors to mark which areas are identified as obstacles and objects that are moving cars on the road and marks the distance of the car from these obstacles.
<br>
<br>
<strong>Checking the Geographical Location from GPS Data:</strong>
<br>
<br>
At this point we have the model of the world around the car and the car is travelling through this space. The highly accurate model of the world is created offline using the data collected by various cars. This GPS data is available for the car to access to identify its geographical location and direction of travel and to find out which lane it is driving in, so that then it can run more algorithms to do motion planning and navigation. This happens using the Localization Algorithm.

<br>
The combined output from the Sensor Fusion and Deep Learning algorithms gives the car information about its location and surroundings which can be used by the ‘path planning algorithm’ to make decisions about how to navigate.</p>

    <!-- <p>All of these sensors are collated in realtime by the car's onboard CPU to create a realistic mapping of the world.
    </p> -->
  </div>

</div>
</div>
</div>
<a href="#about" class="btn btn-circle page-scroll"><i class="fa fa-angle-double-down animated"></i></a>


</section>

<!-- <section>
  <h2>Conclusion</h2>
  <p>On September 19, U.S. auto safety regulators released the <a href="https://www.transportation.gov/AV/federal-automated-vehicles-policy-september-2016">Department of Transportation’s Federal Automated Vehicles Policy</a>, effectively giving tech companies and automakers a greenlight to eliminate human supervision over autonomous vehicles. </p>
</section> -->





<section id="about" class="contact bg-primary">
  <div class="container">
    <h2>About</h2>

  </section>

  <section id="resources" class="contact bg-primary">
    <div class="container">
      <h2>Resources</h2>

    </section>

    <footer>
      <div class="container">
        <p>&copy; 2016 Eve and Nilomee. All Rights Reserved.</p>

      </div>
    </footer>

    <!-- jQuery -->
    <script src="vendor/jquery/jquery.min.js"></script>

    <!-- Bootstrap Core JavaScript -->
    <script src="vendor/bootstrap/js/bootstrap.min.js"></script>

    <!-- Plugin JavaScript -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-easing/1.3/jquery.easing.min.js"></script>

    <!-- Theme JavaScript -->
    <script src="js/new-age.min.js"></script>

  </body>

  </html>
